{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pricing Analysis: Minion vs Standard Models\n",
    "\n",
    "This notebook analyzes and visualizes the pricing differences between Minion and Standard model configurations.\n",
    "\n",
    "## Overview\n",
    "- **Minion Models**: Small, efficient models primarily from HuggingFace for domain-specific tasks\n",
    "- **Standard Models**: High-performance models from major providers for complex tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Configuration\n",
    "\n",
    "### Minion Models (from domain_mappings.py)\n",
    "Domain-specific models optimized for cost-efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minion models from adaptive_ai/config/domain_mappings.py\n",
    "minion_models = {\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": {\"provider\": \"huggingface\"},\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\"provider\": \"huggingface\"},\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": {\"provider\": \"huggingface\"},\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": {\"provider\": \"huggingface\"},\n",
    "}\n",
    "\n",
    "print(\"Minion Models:\")\n",
    "for model in minion_models.keys():\n",
    "    print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Models (from task_mappings.py)\n",
    "High-performance models for complex reasoning and generation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard models from adaptive_ai/config/task_mappings.py (unique models)\n",
    "standard_models = {\n",
    "    \"gpt-4o\": {\"provider\": \"openai\"},\n",
    "    \"claude-3-5-sonnet-20241022\": {\"provider\": \"anthropic\", \"mapped_name\": \"claude-4-sonnet\"},\n",
    "    \"grok-3\": {\"provider\": \"grok\"},\n",
    "    \"deepseek-chat\": {\"provider\": \"deepseek\"},\n",
    "    \"gpt-4o-mini\": {\"provider\": \"openai\"},\n",
    "    \"claude-3-haiku-20240307\": {\"provider\": \"anthropic\", \"mapped_name\": \"claude-3.5-haiku\"},\n",
    "    \"grok-3-mini\": {\"provider\": \"grok\"},\n",
    "    \"llama-3.1-70b-versatile\": {\"provider\": \"groq\", \"mapped_name\": \"llama-3.3-70b-versatile\"},\n",
    "}\n",
    "\n",
    "print(\"Standard Models:\")\n",
    "for model in standard_models.keys():\n",
    "    print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing Data\n",
    "Extracted from `seed-providers.ts` and `providers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing data from seed-providers.ts and providers.py (cost per 1M tokens in USD)\n",
    "pricing_data = {\n",
    "    # OpenAI models\n",
    "    \"gpt-4o\": {\"input\": 2.50, \"output\": 10.00},\n",
    "    \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.60},\n",
    "    \n",
    "    # Anthropic models\n",
    "    \"claude-4-sonnet\": {\"input\": 3.00, \"output\": 15.00},\n",
    "    \"claude-3.5-haiku\": {\"input\": 0.80, \"output\": 4.00},\n",
    "    \n",
    "    # DeepSeek models\n",
    "    \"deepseek-chat\": {\"input\": 0.14, \"output\": 0.28},\n",
    "    \n",
    "    # Grok models\n",
    "    \"grok-3\": {\"input\": 3.00, \"output\": 15.00},\n",
    "    \"grok-3-mini\": {\"input\": 0.30, \"output\": 0.50},\n",
    "    \n",
    "    # Groq models\n",
    "    \"llama-3.3-70b-versatile\": {\"input\": 0.59, \"output\": 0.79},\n",
    "    \n",
    "    # HuggingFace models (all have same pricing in seed-providers.ts)\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": {\"input\": 0.01, \"output\": 0.02},\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\"input\": 0.01, \"output\": 0.02},\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": {\"input\": 0.01, \"output\": 0.02},\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": {\"input\": 0.01, \"output\": 0.02},\n",
    "}\n",
    "\n",
    "print(\"Sample pricing data:\")\n",
    "for model, price in list(pricing_data.items())[:3]:\n",
    "    print(f\"  {model}: Input ${price['input']}, Output ${price['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_pricing(model_name, model_config):\n",
    "    \"\"\"Get pricing for a model, handling name mappings.\"\"\"\n",
    "    # Check if there's a mapped name\n",
    "    lookup_name = model_config.get(\"mapped_name\", model_name)\n",
    "    \n",
    "    if lookup_name in pricing_data:\n",
    "        return pricing_data[lookup_name]\n",
    "    elif model_name in pricing_data:\n",
    "        return pricing_data[model_name]\n",
    "    else:\n",
    "        return {\"input\": 0, \"output\": 0}  # Not found\n",
    "\n",
    "def extract_pricing_data():\n",
    "    \"\"\"Extract pricing data for minion and standard models.\"\"\"\n",
    "    \n",
    "    # Extract minion pricing\n",
    "    minion_data = []\n",
    "    for model, config in minion_models.items():\n",
    "        pricing = get_model_pricing(model, config)\n",
    "        minion_data.append({\n",
    "            \"model\": model.split(\"/\")[-1] if \"/\" in model else model,\n",
    "            \"full_model\": model,\n",
    "            \"provider\": config[\"provider\"],\n",
    "            \"input_cost\": pricing[\"input\"],\n",
    "            \"output_cost\": pricing[\"output\"],\n",
    "            \"category\": \"Minion\"\n",
    "        })\n",
    "    \n",
    "    # Extract standard pricing\n",
    "    standard_data = []\n",
    "    for model, config in standard_models.items():\n",
    "        pricing = get_model_pricing(model, config)\n",
    "        standard_data.append({\n",
    "            \"model\": model,\n",
    "            \"full_model\": model,\n",
    "            \"provider\": config[\"provider\"],\n",
    "            \"input_cost\": pricing[\"input\"],\n",
    "            \"output_cost\": pricing[\"output\"],\n",
    "            \"category\": \"Standard\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(minion_data), pd.DataFrame(standard_data)\n",
    "\n",
    "# Extract the data\n",
    "minion_df, standard_df = extract_pricing_data()\n",
    "\n",
    "print(\"Data extraction complete!\")\n",
    "print(f\"Minion models: {len(minion_df)}\")\n",
    "print(f\"Standard models: {len(standard_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MINION MODELS PRICING\")\n",
    "print(\"=\" * 80)\n",
    "display(minion_df[['model', 'provider', 'input_cost', 'output_cost']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STANDARD MODELS PRICING\")\n",
    "print(\"=\" * 80)\n",
    "display(standard_df[['model', 'provider', 'input_cost', 'output_cost']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1: Separate Input and Output Cost Charts\n",
    "\n",
    "### Minion Models - Input vs Output Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for minion models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle('Minion Models - Input vs Output Costs (per 1M tokens)', fontsize=16, fontweight='bold')\n",
    "\n",
    "minion_color = '#2E8B57'  # Sea Green\n",
    "\n",
    "# Input costs\n",
    "bars1 = ax1.bar(range(len(minion_df)), minion_df['input_cost'], \n",
    "                color=minion_color, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax1.set_title('Input Costs', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Models', fontsize=12)\n",
    "ax1.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax1.set_xticks(range(len(minion_df)))\n",
    "ax1.set_xticklabels(minion_df['model'], rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(minion_df['input_cost']):\n",
    "    ax1.text(i, v + 0.0001, f'${v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Output costs\n",
    "bars2 = ax2.bar(range(len(minion_df)), minion_df['output_cost'], \n",
    "                color=minion_color, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax2.set_title('Output Costs', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Models', fontsize=12)\n",
    "ax2.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax2.set_xticks(range(len(minion_df)))\n",
    "ax2.set_xticklabels(minion_df['model'], rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(minion_df['output_cost']):\n",
    "    ax2.text(i, v + 0.0001, f'${v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Models - Input vs Output Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for standard models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle('Standard Models - Input vs Output Costs (per 1M tokens)', fontsize=16, fontweight='bold')\n",
    "\n",
    "standard_color = '#4169E1'  # Royal Blue\n",
    "\n",
    "# Input costs\n",
    "bars1 = ax1.bar(range(len(standard_df)), standard_df['input_cost'], \n",
    "                color=standard_color, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax1.set_title('Input Costs', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Models', fontsize=12)\n",
    "ax1.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax1.set_xticks(range(len(standard_df)))\n",
    "ax1.set_xticklabels(standard_df['model'], rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(standard_df['input_cost']):\n",
    "    ax1.text(i, v + max(standard_df['input_cost']) * 0.01, f'${v:.2f}', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Output costs\n",
    "bars2 = ax2.bar(range(len(standard_df)), standard_df['output_cost'], \n",
    "                color=standard_color, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax2.set_title('Output Costs', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Models', fontsize=12)\n",
    "ax2.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax2.set_xticks(range(len(standard_df)))\n",
    "ax2.set_xticklabels(standard_df['model'], rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(standard_df['output_cost']):\n",
    "    ax2.text(i, v + max(standard_df['output_cost']) * 0.01, f'${v:.2f}', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2: Direct Comparison - Minion vs Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle('Direct Pricing Comparison: Minion vs Standard Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Combine data for comparison\n",
    "all_models = []\n",
    "input_costs = []\n",
    "output_costs = []\n",
    "categories = []\n",
    "\n",
    "# Add minion models\n",
    "for _, row in minion_df.iterrows():\n",
    "    all_models.append(f\"{row['model']}\\n(Minion)\")\n",
    "    input_costs.append(row['input_cost'])\n",
    "    output_costs.append(row['output_cost'])\n",
    "    categories.append('Minion')\n",
    "\n",
    "# Add standard models\n",
    "for _, row in standard_df.iterrows():\n",
    "    all_models.append(f\"{row['model']}\\n(Standard)\")\n",
    "    input_costs.append(row['input_cost'])\n",
    "    output_costs.append(row['output_cost'])\n",
    "    categories.append('Standard')\n",
    "\n",
    "colors = ['#2E8B57' if cat == 'Minion' else '#4169E1' for cat in categories]\n",
    "\n",
    "# Input costs comparison\n",
    "bars1 = ax1.bar(range(len(all_models)), input_costs, \n",
    "               color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax1.set_title('Input Costs Comparison (per 1M tokens)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Models', fontsize=12)\n",
    "ax1.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax1.set_xticks(range(len(all_models)))\n",
    "ax1.set_xticklabels(all_models, rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')  # Log scale to better show the difference\n",
    "\n",
    "# Output costs comparison\n",
    "bars2 = ax2.bar(range(len(all_models)), output_costs, \n",
    "               color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax2.set_title('Output Costs Comparison (per 1M tokens)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Models', fontsize=12)\n",
    "ax2.set_ylabel('Cost (USD)', fontsize=12)\n",
    "ax2.set_xticks(range(len(all_models)))\n",
    "ax2.set_xticklabels(all_models, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_yscale('log')  # Log scale to better show the difference\n",
    "\n",
    "# Add legends\n",
    "minion_patch = plt.Rectangle((0,0),1,1, color='#2E8B57', alpha=0.7, label='Minion Models')\n",
    "standard_patch = plt.Rectangle((0,0),1,1, color='#4169E1', alpha=0.7, label='Standard Models')\n",
    "ax1.legend(handles=[minion_patch, standard_patch], loc='upper left')\n",
    "ax2.legend(handles=[minion_patch, standard_patch], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 3: Cost Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot showing input vs output costs\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot minion models\n",
    "ax.scatter(minion_df['input_cost'], minion_df['output_cost'], \n",
    "          s=200, alpha=0.7, color='#2E8B57', label='Minion Models', edgecolors='black')\n",
    "\n",
    "# Plot standard models\n",
    "ax.scatter(standard_df['input_cost'], standard_df['output_cost'], \n",
    "          s=200, alpha=0.7, color='#4169E1', label='Standard Models', edgecolors='black')\n",
    "\n",
    "# Add model labels\n",
    "for _, row in minion_df.iterrows():\n",
    "    ax.annotate(row['model'], (row['input_cost'], row['output_cost']), \n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "for _, row in standard_df.iterrows():\n",
    "    ax.annotate(row['model'], (row['input_cost'], row['output_cost']), \n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('Input Cost (USD per 1M tokens)', fontsize=12)\n",
    "ax.set_ylabel('Output Cost (USD per 1M tokens)', fontsize=12)\n",
    "ax.set_title('Input vs Output Cost Analysis', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "minion_stats = {\n",
    "    'avg_input': minion_df['input_cost'].mean(),\n",
    "    'avg_output': minion_df['output_cost'].mean(),\n",
    "    'min_input': minion_df['input_cost'].min(),\n",
    "    'max_input': minion_df['input_cost'].max(),\n",
    "    'min_output': minion_df['output_cost'].min(),\n",
    "    'max_output': minion_df['output_cost'].max(),\n",
    "}\n",
    "\n",
    "standard_stats = {\n",
    "    'avg_input': standard_df['input_cost'].mean(),\n",
    "    'avg_output': standard_df['output_cost'].mean(),\n",
    "    'min_input': standard_df['input_cost'].min(),\n",
    "    'max_input': standard_df['input_cost'].max(),\n",
    "    'min_output': standard_df['output_cost'].min(),\n",
    "    'max_output': standard_df['output_cost'].max(),\n",
    "}\n",
    "\n",
    "# Create summary table\n",
    "summary_data = {\n",
    "    'Metric': ['Average Input Cost', 'Average Output Cost', 'Min Input Cost', 'Max Input Cost', 'Min Output Cost', 'Max Output Cost'],\n",
    "    'Minion Models': [f\"${minion_stats['avg_input']:.3f}\", f\"${minion_stats['avg_output']:.3f}\", \n",
    "                     f\"${minion_stats['min_input']:.3f}\", f\"${minion_stats['max_input']:.3f}\",\n",
    "                     f\"${minion_stats['min_output']:.3f}\", f\"${minion_stats['max_output']:.3f}\"],\n",
    "    'Standard Models': [f\"${standard_stats['avg_input']:.2f}\", f\"${standard_stats['avg_output']:.2f}\", \n",
    "                       f\"${standard_stats['min_input']:.2f}\", f\"${standard_stats['max_input']:.2f}\",\n",
    "                       f\"${standard_stats['min_output']:.2f}\", f\"${standard_stats['max_output']:.2f}\"]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PRICING SUMMARY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "display(summary_df)\n",
    "\n",
    "# Calculate cost differences\n",
    "input_ratio = standard_stats['avg_input'] / minion_stats['avg_input'] if minion_stats['avg_input'] > 0 else float('inf')\n",
    "output_ratio = standard_stats['avg_output'] / minion_stats['avg_output'] if minion_stats['avg_output'] > 0 else float('inf')\n",
    "\n",
    "print(\"\\nCOST DIFFERENCE ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Standard models cost {input_ratio:.1f}x more for input tokens\")\n",
    "print(f\"Standard models cost {output_ratio:.1f}x more for output tokens\")\n",
    "print(f\"Input cost difference: ${standard_stats['avg_input'] - minion_stats['avg_input']:.3f} per 1M tokens\")\n",
    "print(f\"Output cost difference: ${standard_stats['avg_output'] - minion_stats['avg_output']:.3f} per 1M tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Efficiency Analysis\n",
    "\n",
    "Let's analyze the cost efficiency for a hypothetical workload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate costs for different workload scenarios\n",
    "scenarios = {\n",
    "    'Light Usage': {'input_tokens': 1_000_000, 'output_tokens': 500_000},\n",
    "    'Medium Usage': {'input_tokens': 10_000_000, 'output_tokens': 5_000_000},\n",
    "    'Heavy Usage': {'input_tokens': 100_000_000, 'output_tokens': 50_000_000}\n",
    "}\n",
    "\n",
    "def calculate_workload_cost(input_tokens, output_tokens, df):\n",
    "    \"\"\"Calculate total cost for a workload using average pricing.\"\"\"\n",
    "    avg_input_cost = df['input_cost'].mean()\n",
    "    avg_output_cost = df['output_cost'].mean()\n",
    "    \n",
    "    total_cost = (avg_input_cost * input_tokens / 1_000_000) + (avg_output_cost * output_tokens / 1_000_000)\n",
    "    return total_cost\n",
    "\n",
    "# Calculate costs for each scenario\n",
    "scenario_results = []\n",
    "for scenario_name, workload in scenarios.items():\n",
    "    minion_cost = calculate_workload_cost(workload['input_tokens'], workload['output_tokens'], minion_df)\n",
    "    standard_cost = calculate_workload_cost(workload['input_tokens'], workload['output_tokens'], standard_df)\n",
    "    savings = standard_cost - minion_cost\n",
    "    savings_pct = (savings / standard_cost) * 100 if standard_cost > 0 else 0\n",
    "    \n",
    "    scenario_results.append({\n",
    "        'Scenario': scenario_name,\n",
    "        'Input Tokens': f\"{workload['input_tokens']:,}\",\n",
    "        'Output Tokens': f\"{workload['output_tokens']:,}\",\n",
    "        'Minion Cost': f\"${minion_cost:.2f}\",\n",
    "        'Standard Cost': f\"${standard_cost:.2f}\",\n",
    "        'Savings': f\"${savings:.2f}\",\n",
    "        'Savings %': f\"{savings_pct:.1f}%\"\n",
    "    })\n",
    "\n",
    "scenario_df = pd.DataFrame(scenario_results)\n",
    "\n",
    "print(\"\\nWORKLOAD COST COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "display(scenario_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Cost Efficiency**: Minion models are significantly more cost-effective, with costs that are orders of magnitude lower than standard models.\n",
    "\n",
    "2. **Uniform Pricing**: All minion models from HuggingFace have the same pricing structure ($0.01 input, $0.02 output per 1M tokens).\n",
    "\n",
    "3. **High Variance in Standard Models**: Standard model pricing varies widely, from budget options like DeepSeek Chat to premium models like Claude and Grok.\n",
    "\n",
    "4. **Use Case Optimization**: The system is designed to route simpler, domain-specific tasks to cost-efficient minion models while reserving expensive standard models for complex reasoning tasks.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "- Use minion models for domain-specific, routine tasks to maximize cost efficiency\n",
    "- Reserve standard models for complex reasoning, creative tasks, and critical applications\n",
    "- Consider the 100x+ cost difference when designing workload routing strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}