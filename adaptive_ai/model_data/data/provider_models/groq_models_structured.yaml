provider_info:
  name: GROQ
  total_models: 20
  data_source: https://helicone.ai/api/llm-costs?provider=groq
  last_updated: '2025-08-06'
  currency: USD
  pricing_unit: per 1 million tokens
models:
  deepseek_r1_distill_llama_70b:
    description: The deepseek-r1-distill-llama-70b model is a sophisticated language
      model designed for various tasks, including text generation and classification,
      leveraging a large context window for complex interactions.
    provider: GROQ
    model_name: deepseek-r1-distill-llama-70b
    cost_per_1m_input_tokens: 0.75
    cost_per_1m_output_tokens: 0.99
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572379.8369126
  gemma_7b_it:
    description: GROQ's gemma-7b-it is a 7 billion parameter model designed for various
      tasks, likely including text generation and classification, based on its size
      and naming conventions.
    provider: GROQ
    model_name: gemma-7b-it
    cost_per_1m_input_tokens: 0.07
    cost_per_1m_output_tokens: 0.07
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 7b
    latency_tier: medium
    task_type: Other
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754572383.0406604
  gemma2_9b_it:
    description: gemma2-9b-it is a language model designed for various natural language
      processing tasks, likely optimized for text generation and classification based
      on its size and context capabilities.
    provider: GROQ
    model_name: gemma2-9b-it
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 9b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754572386.158196
  llama_3.1_8b_instant:
    description: Llama-3.1-8b-instant is a state-of-the-art language model designed
      for efficient natural language processing tasks, offering robust capabilities
      for text generation and conversational applications.
    provider: GROQ
    model_name: llama-3.1-8b-instant
    cost_per_1m_input_tokens: 0.05
    cost_per_1m_output_tokens: 0.08
    max_context_tokens: 10000
    max_output_tokens: 2500
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572389.0082624
  llama_3.3_70b_versatile:
    description: The GROQ Llama 3.3 70B Versatile model is a high-performance AI solution
      designed for a wide range of applications, including text generation, classification,
      and more, leveraging a large context window for complex tasks.
    provider: GROQ
    model_name: llama-3.3-70b-versatile
    cost_per_1m_input_tokens: 0.59
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 131072
    max_output_tokens: 32768
    supports_function_calling: true
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572392.0783393
  llama_guard_3_8b:
    description: Llama-guard-3-8b is a model designed for various language tasks,
      likely optimized for text generation and classification, with a focus on handling
      social media content and integration with APIs.
    provider: GROQ
    model_name: llama-guard-3-8b
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Classification
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572396.324991
  llama2_70b_4096:
    description: The Llama2-70b-4096 model by GROQ is a large language model designed
      for advanced text generation and conversational tasks, leveraging a substantial
      parameter count for sophisticated reasoning and contextual understanding.
    provider: GROQ
    model_name: llama2-70b-4096
    cost_per_1m_input_tokens: 0.7
    cost_per_1m_output_tokens: 0.8
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572401.529591
  llama3_70b_8192:
    description: The GROQ llama3-70b-8192 is a large language model designed for advanced
      text generation and processing tasks, capable of handling complex queries and
      providing sophisticated responses.
    provider: GROQ
    model_name: llama3-70b-8192
    cost_per_1m_input_tokens: 0.59
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572404.4174988
  llama3_8b_8192:
    description: Llama3-8b-8192 is a large language model designed for versatile applications,
      including text generation and classification tasks, with a focus on accessibility
      for various users.
    provider: GROQ
    model_name: llama3-8b-8192
    cost_per_1m_input_tokens: 0.05
    cost_per_1m_output_tokens: 0.08
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572407.2107868
  llama3_groq_70b_8192_tool_use_preview:
    description: The Llama3-GROQ-70B-8192-Tool-Use-Preview is a large language model
      designed for advanced text generation and tool usage, leveraging a substantial
      context window for complex tasks.
    provider: GROQ
    model_name: llama3-groq-70b-8192-tool-use-preview
    cost_per_1m_input_tokens: 0.89
    cost_per_1m_output_tokens: 0.89
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_function_calling: true
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572409.853268
  llama3_groq_8b_8192_tool_use_preview:
    description: The Llama3-GROQ-8B-8192-Tool-Use-Preview model is a large language
      model designed for versatile applications, including text generation and tool
      usage, with a focus on accessibility for various users.
    provider: GROQ
    model_name: llama3-groq-8b-8192-tool-use-preview
    cost_per_1m_input_tokens: 0.19
    cost_per_1m_output_tokens: 0.19
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_function_calling: true
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572412.715802
  meta_llama_llama_4_maverick_17b_128e_instruct:
    description: The meta-llama/llama-4-maverick-17b-128e-instruct model is a sophisticated
      language model designed for various natural language processing tasks, likely
      optimized for instruction-following capabilities.
    provider: GROQ
    model_name: meta-llama/llama-4-maverick-17b-128e-instruct
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.6
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 17b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572415.4070055
  meta_llama_llama_4_scout_17b_16e_instruct:
    description: The meta-llama/llama-4-scout-17b-16e-instruct model is a sophisticated
      language model designed for high-performance text generation and complex tasks,
      featuring a large context window and support for multiple languages.
    provider: GROQ
    model_name: meta-llama/llama-4-scout-17b-16e-instruct
    cost_per_1m_input_tokens: 0.11
    cost_per_1m_output_tokens: 0.34
    max_context_tokens: 128000
    max_output_tokens: 32000
    supports_function_calling: false
    languages_supported:
    - Arabic
    - English
    - French
    - German
    - Hindi
    model_size_params: 17b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572418.1925013
  meta_llama_llama_guard_4_12b:
    description: The meta-llama/llama-guard-4-12b model is designed for advanced language
      processing tasks, likely incorporating features for text generation and possibly
      classification, given its size and context capabilities.
    provider: GROQ
    model_name: meta-llama/llama-guard-4-12b
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 12b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754572420.8145378
  mistral_saba_24b:
    description: The mistral-saba-24b model by GROQ is a large language model designed
      for various natural language processing tasks, potentially including text generation
      and classification, though specific capabilities are not detailed in the search
      results.
    provider: GROQ
    model_name: mistral-saba-24b
    cost_per_1m_input_tokens: 0.79
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 24b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754572423.4263394
  mixtral_8x7b_32768:
    description: Mixtral-8x7b-32768 is a sophisticated language model designed for
      high-performance AI tasks, featuring a large context window and optimized for
      various applications including chat completion and transcription.
    provider: GROQ
    model_name: mixtral-8x7b-32768
    cost_per_1m_input_tokens: 0.24
    cost_per_1m_output_tokens: 0.24
    max_context_tokens: 32768
    max_output_tokens: 8192
    supports_function_calling: true
    languages_supported:
    - English
    model_size_params: 8x7b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572426.8730876
  moonshotai_kimi_k2_instruct:
    description: The moonshotai/kimi-k2-instruct model is designed for instruction-following
      tasks, likely optimized for generating responses based on user prompts in a
      conversational context.
    provider: GROQ
    model_name: moonshotai/kimi-k2-instruct
    cost_per_1m_input_tokens: 1.0
    cost_per_1m_output_tokens: 3.0
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: Unknown
    latency_tier: medium
    task_type: Chatbot
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754572429.6223764
  openai_gpt_oss_120b:
    description: The openai/gpt-oss-120b model is a large language model designed
      for advanced text generation and conversational tasks, leveraging a substantial
      parameter count for sophisticated reasoning and context handling.
    provider: GROQ
    model_name: openai/gpt-oss-120b
    cost_per_1m_input_tokens: 0.15
    cost_per_1m_output_tokens: 0.75
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_function_calling: false
    languages_supported:
    - English
    model_size_params: 120b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754572432.0929277
  openai_gpt_oss_20b:
    description: gpt-oss-20b is an open-weight language model designed for powerful
      reasoning and versatile developer use cases, capable of function calling, web
      browsing, and Python code execution.
    provider: GROQ
    model_name: openai/gpt-oss-20b
    cost_per_1m_input_tokens: 0.1
    cost_per_1m_output_tokens: 0.5
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_function_calling: true
    languages_supported:
    - English
    model_size_params: 20b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754572435.188306
  qwen_qwen3_32b:
    description: Qwen3-32B is a state-of-the-art language model optimized for complex
      reasoning and efficient dialogue, capable of handling sophisticated tasks and
      coding capabilities.
    provider: GROQ
    model_name: qwen/qwen3-32b
    cost_per_1m_input_tokens: 0.29
    cost_per_1m_output_tokens: 0.59
    max_context_tokens: 131072
    max_output_tokens: 32768
    supports_function_calling: true
    languages_supported:
    - English
    - Chinese
    model_size_params: 32b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    metadata:
      matching_operator: equals
      available_in_playground: null
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754574067.115139
