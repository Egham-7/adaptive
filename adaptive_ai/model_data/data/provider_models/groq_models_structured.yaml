provider_info:
  name: GROQ
provider_info:
  total_models: 21
  data_source: https://helicone.ai/api/llm-costs?provider=groq
  last_updated: '2025-08-09'
  currency: USD
  pricing_unit: per 1 million tokens
models:
  deepseek_r1_distill_llama_70b:
    description: The deepseek-r1-distill-llama-70b model is a sophisticated language
      model designed for various tasks, including text generation and classification,
      leveraging a large context window for complex interactions.
    provider: GROQ
    model_name: deepseek-r1-distill-llama-70b
    cost_per_1m_input_tokens: 0.75
    cost_per_1m_output_tokens: 0.99
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742390.020361
  gemma_7b_it:
    description: GROQ's gemma-7b-it is a 7 billion parameter model designed for various
      tasks, likely including text generation and classification, based on its size
      and naming conventions.
    provider: GROQ
    model_name: gemma-7b-it
    cost_per_1m_input_tokens: 0.07
    cost_per_1m_output_tokens: 0.07
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 7b
    latency_tier: medium
    task_type: Other
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742392.672132
  gemma2_9b_it:
    description: gemma2-9b-it is a language model designed for various natural language
      processing tasks, likely optimized for text generation and classification based
      on its size and context capabilities.
    provider: GROQ
    model_name: gemma2-9b-it
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 9b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742395.027393
  llama_3_1_8b_instant:
    description: Llama-3.1-8b-instant is a mid-sized language model designed for efficient
      text generation and conversational tasks, leveraging advanced capabilities for
      quick responses.
    provider: GROQ
    model_name: llama-3.1-8b-instant
    cost_per_1m_input_tokens: 0.05
    cost_per_1m_output_tokens: 0.08
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Chatbot
    complexity: easy
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742397.587641
  llama_3_3_70b_versatile:
    description: Llama-3.3-70b-versatile is a large language model designed for a
      wide range of tasks, including text generation and conversational interactions,
      leveraging its extensive parameter count for sophisticated reasoning and contextual
      understanding.
    provider: GROQ
    model_name: llama-3.3-70b-versatile
    cost_per_1m_input_tokens: 0.59
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742400.455114
  llama_guard_3_8b:
    description: Llama-guard-3-8b is a model designed for various language tasks,
      likely optimized for text generation and classification, with a focus on handling
      social media content and integration with APIs.
    provider: GROQ
    model_name: llama-guard-3-8b
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Classification
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742404.9026408
  llama2_70b_4096:
    description: The Llama2-70b-4096 model by GROQ is a large language model designed
      for advanced text generation and conversational tasks, leveraging a substantial
      parameter count for sophisticated reasoning and contextual understanding.
    provider: GROQ
    model_name: llama2-70b-4096
    cost_per_1m_input_tokens: 0.7
    cost_per_1m_output_tokens: 0.8
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754742407.624161
  llama3_70b_8192:
    description: The GROQ llama3-70b-8192 is a large language model designed for advanced
      text generation and processing tasks, capable of handling complex queries and
      providing sophisticated responses.
    provider: GROQ
    model_name: llama3-70b-8192
    cost_per_1m_input_tokens: 0.59
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.9
      enriched_at: 1754742410.390282
  llama3_8b_8192:
    description: Llama3-8b-8192 is a large language model designed for versatile applications,
      including text generation and classification tasks, with a focus on accessibility
      for various users.
    provider: GROQ
    model_name: llama3-8b-8192
    cost_per_1m_input_tokens: 0.05
    cost_per_1m_output_tokens: 0.08
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Text Generation
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742413.485157
  llama3_groq_70b_8192_tool_use_preview:
    description: The Llama3-GROQ-70B-8192-Tool-Use-Preview is a large language model
      designed for advanced text generation and tool usage, leveraging a substantial
      context window for complex tasks.
    provider: GROQ
    model_name: llama3-groq-70b-8192-tool-use-preview
    cost_per_1m_input_tokens: 0.89
    cost_per_1m_output_tokens: 0.89
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
  llama3_groq_8b_8192_tool_use_preview:
    description: The Llama3-GROQ-8B-8192-Tool-Use-Preview model is a large language
      model designed for versatile applications, including text generation and tool
      usage, with a focus on accessibility for various users.
    provider: GROQ
    model_name: llama3-groq-8b-8192-tool-use-preview
    cost_per_1m_input_tokens: 0.19
    cost_per_1m_output_tokens: 0.19
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 8b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
  meta_llama_llama_4_maverick_17b_128e_instruct:
    description: The meta-llama/llama-4-maverick-17b-128e-instruct model is a sophisticated
      language model designed for various natural language processing tasks, likely
      optimized for instruction-following capabilities.
    provider: GROQ
    model_name: meta-llama/llama-4-maverick-17b-128e-instruct
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.6
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 17b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.85
      enriched_at: 1754742416.227683
  meta_llama_llama_4_scout_17b_16e_instruct:
    description: The meta-llama/llama-4-scout-17b-16e-instruct model is a sophisticated
      language model designed for high-performance text generation and complex tasks,
      featuring a large context window and support for multiple languages.
    provider: GROQ
    model_name: meta-llama/llama-4-scout-17b-16e-instruct
    cost_per_1m_input_tokens: 0.11
    cost_per_1m_output_tokens: 0.34
    max_context_tokens: 128000
    max_output_tokens: 32000
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - Arabic
    - English
    - French
    - German
    - Hindi
    model_size_params: 17b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742558.664875
  meta_llama_llama_guard_4_12b:
    description: The meta-llama/llama-guard-4-12b model is designed for advanced language
      processing tasks, likely incorporating features for text generation and possibly
      classification, given its size and context capabilities.
    provider: GROQ
    model_name: meta-llama/llama-guard-4-12b
    cost_per_1m_input_tokens: 0.2
    cost_per_1m_output_tokens: 0.2
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 12b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742561.633247
  mistral_saba_24b:
    description: The mistral-saba-24b model by GROQ is a large language model designed
      for various natural language processing tasks, potentially including text generation
      and classification, though specific capabilities are not detailed in the search
      results.
    provider: GROQ
    model_name: mistral-saba-24b
    cost_per_1m_input_tokens: 0.79
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 24b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742564.605484
  mixtral_8x7b_32768:
    description: Mixtral-8x7b-32768 is a sophisticated language model designed for
      high-performance AI tasks, featuring a large context window and optimized for
      various applications including chat completion and transcription.
    provider: GROQ
    model_name: mixtral-8x7b-32768
    cost_per_1m_input_tokens: 0.24
    cost_per_1m_output_tokens: 0.24
    max_context_tokens: 32768
    max_output_tokens: 8192
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 8x7b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
  moonshotai_kimi_k2_instruct:
    description: The moonshotai/kimi-k2-instruct model is designed for instruction-following
      tasks, likely optimized for generating responses based on user prompts in a
      conversational context.
    provider: GROQ
    model_name: moonshotai/kimi-k2-instruct
    cost_per_1m_input_tokens: 1
    cost_per_1m_output_tokens: 3
    max_context_tokens: 4096
    max_output_tokens: 1024
    supports_streaming: true
    supports_function_calling: false
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: Unknown
    latency_tier: medium
    task_type: Brainstorming
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.7
      enriched_at: 1754742567.368334
  openai_gpt_oss_120b:
    description: The openai/gpt-oss-120b model is a large language model designed
      for advanced text generation and conversational tasks, leveraging a substantial
      parameter count for sophisticated reasoning and context handling.
    provider: GROQ
    model_name: openai/gpt-oss-120b
    cost_per_1m_input_tokens: 0.15
    cost_per_1m_output_tokens: 0.75
    max_context_tokens: 8192
    max_output_tokens: 2048
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 120b
    latency_tier: slow
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: langgraph_workflow
      confidence_score: 0.8
      enriched_at: 1754742570.64694
  openai_gpt_oss_20b:
    description: gpt-oss-20b is an open-weight language model designed for powerful
      reasoning and versatile developer use cases, capable of function calling, web
      browsing, and Python code execution.
    provider: GROQ
    model_name: openai/gpt-oss-20b
    cost_per_1m_input_tokens: 0.1
    cost_per_1m_output_tokens: 0.5
    max_context_tokens: 2048
    max_output_tokens: 512
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 20b
    latency_tier: medium
    task_type: Code Generation
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
  qwen_qwen3_32b:
    description: Qwen3-32B is a state-of-the-art language model optimized for complex
      reasoning and efficient dialogue, capable of handling sophisticated tasks and
      coding capabilities.
    provider: GROQ
    model_name: qwen/qwen3-32b
    cost_per_1m_input_tokens: 0.29
    cost_per_1m_output_tokens: 0.59
    max_context_tokens: 131072
    max_output_tokens: 32768
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    - Chinese
    model_size_params: 32b
    latency_tier: medium
    task_type: Text Generation
    complexity: hard
    release_date: null
    training_data_cutoff: null
    metadata:
      source: helicone_api
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
  llama_3_1_70b_versatile:
    description: Llama 3.1 70B model optimized for fast inference and cost efficiency.
    provider: GROQ
    model_name: llama-3.1-70b-versatile
    cost_per_1m_input_tokens: 0.59
    cost_per_1m_output_tokens: 0.79
    max_context_tokens: 131072
    max_output_tokens: 4096
    supports_streaming: true
    supports_function_calling: true
    supports_vision: null
    multimodal_capabilities:
    - text
    languages_supported:
    - English
    model_size_params: 70B
    latency_tier: very low
    task_type: general
    complexity: medium
    release_date: null
    training_data_cutoff: null
    metadata:
      source: adaptive_ai_config
      last_updated: '2025-08-09'
      matching_operator: equals
      available_in_playground: true
    _enrichment:
      enriched: true
      method: adaptive_ai_migration
      confidence_score: 1.0
      enriched_at: 1754742835.0
