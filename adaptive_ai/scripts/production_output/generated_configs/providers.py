"""
Provider configurations and model capabilities for all supported providers.
Generated automatically by Model Capability Agent.
"""

from adaptive_ai.models.llm_core_models import ModelCapability
from adaptive_ai.models.llm_enums import ProviderType

# Model capabilities for all providers
provider_model_capabilities: dict[ProviderType, list[ModelCapability]] = {
    ProviderType.GROQ: [
        ModelCapability(
            description="AI model with high complexity",
            provider=ProviderType.GROQ,
            model_name="llama-3.1-70b-versatile",
            cost_per_1m_input_tokens=0.59,
            cost_per_1m_output_tokens=0.79,
            max_context_tokens=131072,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="general",
            complexity="high",
        ),
    ],
    ProviderType.DEEPSEEK: [
        ModelCapability(
            description="AI model with medium complexity",
            provider=ProviderType.DEEPSEEK,
            model_name="deepseek-chat",
            cost_per_1m_input_tokens=0.14,
            cost_per_1m_output_tokens=0.28,
            max_context_tokens=128000,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="low",
            task_type="code",
            complexity="medium",
        ),
        ModelCapability(
            description="AI model with expert complexity",
            provider=ProviderType.DEEPSEEK,
            model_name="deepseek-reasoner",
            cost_per_1m_input_tokens=0.55,
            cost_per_1m_output_tokens=2.19,
            max_context_tokens=128000,
            max_output_tokens=4096,
            supports_function_calling=False,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="code",
            complexity="expert",
        ),
    ],
    ProviderType.GROK: [
        ModelCapability(
            description="AI model with low complexity",
            provider=ProviderType.GROK,
            model_name="grok-3-mini",
            cost_per_1m_input_tokens=0.1,
            cost_per_1m_output_tokens=0.3,
            max_context_tokens=32768,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="very_low",
            task_type="general",
            complexity="low",
        ),
    ],
    ProviderType.ANTHROPIC: [
        ModelCapability(
            description="AI model with low complexity",
            provider=ProviderType.ANTHROPIC,
            model_name="claude-3-5-haiku-20241022",
            cost_per_1m_input_tokens=0.8,
            cost_per_1m_output_tokens=4.0,
            max_context_tokens=200000,
            max_output_tokens=8192,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="very_low",
            task_type="creative",
            complexity="low",
        ),
        ModelCapability(
            description="AI model with expert complexity",
            provider=ProviderType.ANTHROPIC,
            model_name="claude-sonnet-4-20250514",
            cost_per_1m_input_tokens=3.0,
            cost_per_1m_output_tokens=15.0,
            max_context_tokens=200000,
            max_output_tokens=8192,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="creative",
            complexity="expert",
        ),
        ModelCapability(
            description="AI model with expert complexity",
            provider=ProviderType.ANTHROPIC,
            model_name="claude-opus-4-20250514",
            cost_per_1m_input_tokens=15.0,
            cost_per_1m_output_tokens=75.0,
            max_context_tokens=200000,
            max_output_tokens=8192,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="creative",
            complexity="expert",
        ),
    ],
    ProviderType.OPENAI: [
        ModelCapability(
            description="AI model with high complexity",
            provider=ProviderType.OPENAI,
            model_name="gpt-4",
            cost_per_1m_input_tokens=30.0,
            cost_per_1m_output_tokens=60.0,
            max_context_tokens=8192,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="general",
            complexity="high",
        ),
        ModelCapability(
            description="AI model with high complexity",
            provider=ProviderType.OPENAI,
            model_name="gpt-4-turbo",
            cost_per_1m_input_tokens=10.0,
            cost_per_1m_output_tokens=30.0,
            max_context_tokens=128000,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="general",
            complexity="high",
        ),
        ModelCapability(
            description="AI model with expert complexity",
            provider=ProviderType.OPENAI,
            model_name="gpt-4o",
            cost_per_1m_input_tokens=5.0,
            cost_per_1m_output_tokens=15.0,
            max_context_tokens=128000,
            max_output_tokens=4096,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="general",
            complexity="expert",
        ),
        ModelCapability(
            description="AI model with expert complexity",
            provider=ProviderType.OPENAI,
            model_name="gpt-4o-mini",
            cost_per_1m_input_tokens=0.15,
            cost_per_1m_output_tokens=0.6,
            max_context_tokens=128000,
            max_output_tokens=16384,
            supports_function_calling=True,
            languages_supported=['en'],
            model_size_params="Unknown",
            latency_tier="medium",
            task_type="general",
            complexity="expert",
        ),
    ]
}
