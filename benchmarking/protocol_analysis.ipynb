{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Adaptive AI Protocol Routing Analysis\n",
    "\n",
    "This notebook provides comprehensive testing and analysis of the rule-based protocol selection system.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ **Clean API Integration** - Proper error handling and retry logic\n",
    "- ‚úÖ **Flexible Dataset Testing** - Easy configuration for different datasets\n",
    "- ‚úÖ **Real-time Monitoring** - Progress tracking and performance metrics\n",
    "- ‚úÖ **Comprehensive Analysis** - Detailed insights and visualizations\n",
    "- ‚úÖ **Export Capabilities** - CSV and JSON export for further analysis\n",
    "\n",
    "## Protocol Logic:\n",
    "- **STANDARD**: `request_has_tools` OR `complexity_score > 0.40` OR `token_count > 3000` OR `number_of_few_shots > 4` OR `reasoning > 0.70`\n",
    "- **MINION**: Otherwise (for efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Protocol Analysis Notebook v2.0\n",
      "‚úÖ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Protocol Analysis Notebook v2.0\")\n",
    "print(\"‚úÖ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration loaded:\n",
      "   - API endpoint: http://localhost:8000/predict\n",
      "   - Test sample size: 100 prompts\n",
      "   - Rate limit: 20.0 requests/second\n",
      "   - Tools testing: 50 prompts\n"
     ]
    }
   ],
   "source": [
    "# Service Configuration\n",
    "API_CONFIG = {\n",
    "    \"base_url\": \"http://localhost:8000\",\n",
    "    \"endpoint\": \"/predict\",\n",
    "    \"timeout\": 30,\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 0.5,\n",
    "}\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET_CONFIG = {\n",
    "    \"routellm_gpt4\": {\n",
    "        \"name\": \"routellm/gpt4_dataset\",\n",
    "        \"split\": \"validation\",\n",
    "        \"prompt_column\": \"prompt\",\n",
    "        \"description\": \"High-quality GPT-4 prompts from RouteLL\",\n",
    "        \"sample_size\": None,  # None = use all data\n",
    "    }\n",
    "}\n",
    "\n",
    "# Testing Configuration\n",
    "TEST_CONFIG = {\n",
    "    \"sample_size\": 100,  # Number of prompts to test (for quick testing)\n",
    "    \"rate_limit_delay\": 0.05,  # Delay between requests (seconds)\n",
    "    \"progress_interval\": 1000,  # Report progress every N prompts\n",
    "    \"tools_test_size\": 50,  # Number of prompts to test with tools\n",
    "    \"max_consecutive_failures\": 5,  # Stop after N consecutive failures\n",
    "}\n",
    "\n",
    "print(\"üîß Configuration loaded:\")\n",
    "print(f\"   - API endpoint: {API_CONFIG['base_url']}{API_CONFIG['endpoint']}\")\n",
    "print(f\"   - Test sample size: {TEST_CONFIG['sample_size']} prompts\")\n",
    "print(f\"   - Rate limit: {1/TEST_CONFIG['rate_limit_delay']:.1f} requests/second\")\n",
    "print(f\"   - Tools testing: {TEST_CONFIG['tools_test_size']} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-section",
   "metadata": {},
   "source": [
    "## API Client & Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "api-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API connection successful!\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveAIClient:\n",
    "    \"\"\"Clean API client for the Adaptive AI service.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict):\n",
    "        self.base_url = config[\"base_url\"]\n",
    "        self.endpoint = config[\"endpoint\"]\n",
    "        self.timeout = config[\"timeout\"]\n",
    "        self.max_retries = config[\"max_retries\"]\n",
    "        self.retry_delay = config[\"retry_delay\"]\n",
    "        self.url = f\"{self.base_url}{self.endpoint}\"\n",
    "\n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test if the service is available.\"\"\"\n",
    "        try:\n",
    "            response = self.query([{\"role\": \"user\", \"content\": \"test\"}])\n",
    "            return response is not None\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def query(\n",
    "        self, messages: List[Dict], tools: Optional[List[Dict]] = None, **kwargs\n",
    "    ) -> Optional[Dict]:\n",
    "        \"\"\"Send a request to the Adaptive AI service with retry logic.\"\"\"\n",
    "        payload = {\"messages\": messages}\n",
    "        if tools:\n",
    "            payload[\"tools\"] = tools\n",
    "        payload.update(kwargs)\n",
    "\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = requests.post(self.url, json=payload, timeout=self.timeout)\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if attempt == self.max_retries - 1:  # Last attempt\n",
    "                    print(\n",
    "                        f\"HTTP Error {e.response.status_code}: {e.response.text[:100]}...\"\n",
    "                    )\n",
    "                    return None\n",
    "                time.sleep(self.retry_delay * (attempt + 1))\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt == self.max_retries - 1:  # Last attempt\n",
    "                    print(f\"Request failed: {str(e)[:100]}...\")\n",
    "                    return None\n",
    "                time.sleep(self.retry_delay * (attempt + 1))\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt == self.max_retries - 1:  # Last attempt\n",
    "                    print(f\"Unexpected error: {str(e)[:100]}...\")\n",
    "                    return None\n",
    "                time.sleep(self.retry_delay * (attempt + 1))\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initialize client\n",
    "client = AdaptiveAIClient(API_CONFIG)\n",
    "\n",
    "# Test connection\n",
    "if client.test_connection():\n",
    "    print(\"‚úÖ API connection successful!\")\n",
    "else:\n",
    "    print(\"‚ùå API connection failed!\")\n",
    "    print(\"üí° Make sure the service is running: uv run python main.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comprehensive-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running comprehensive API tests...\n",
      "==================================================\n",
      "\n",
      "1. Testing Basic functionality...\n",
      "   ‚úÖ PASS - Protocol: minion\n",
      "\n",
      "2. Testing Tools functionality...\n",
      "   ‚úÖ PASS - Protocol: standard_llm\n",
      "\n",
      "3. Testing Complex prompt...\n",
      "   ‚úÖ PASS - Protocol: minion\n",
      "\n",
      "4. Testing rapid requests...\n",
      "   ‚úÖ PASS - 3/3 successful\n",
      "\n",
      "‚úÖ All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def run_comprehensive_api_test(client: AdaptiveAIClient) -> bool:\n",
    "    \"\"\"Run comprehensive API tests to verify functionality.\"\"\"\n",
    "    print(\"üß™ Running comprehensive API tests...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    tests = [\n",
    "        {\n",
    "            \"name\": \"Basic functionality\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            \"tools\": None,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Tools functionality\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Calculate 5+5\"}],\n",
    "            \"tools\": [\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"calculate\",\n",
    "                        \"description\": \"Calculate expressions\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\"expr\": {\"type\": \"string\"}},\n",
    "                            \"required\": [\"expr\"],\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Complex prompt\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Explain quantum computing algorithms with mathematical detail\",\n",
    "                }\n",
    "            ],\n",
    "            \"tools\": None,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for i, test in enumerate(tests, 1):\n",
    "        print(f\"\\n{i}. Testing {test['name']}...\")\n",
    "        response = client.query(test[\"messages\"], test[\"tools\"])\n",
    "        success = response is not None\n",
    "        results.append(success)\n",
    "\n",
    "        if success:\n",
    "            protocol = response.get(\"protocol\", \"unknown\")\n",
    "            print(f\"   ‚úÖ PASS - Protocol: {protocol}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå FAIL\")\n",
    "\n",
    "    # Test rapid requests\n",
    "    print(\"\\n4. Testing rapid requests...\")\n",
    "    rapid_success = 0\n",
    "    for i in range(3):\n",
    "        resp = client.query([{\"role\": \"user\", \"content\": f\"Test {i}\"}])\n",
    "        if resp:\n",
    "            rapid_success += 1\n",
    "\n",
    "    results.append(rapid_success >= 2)\n",
    "    print(\n",
    "        f\"   {'‚úÖ PASS' if rapid_success >= 2 else '‚ùå FAIL'} - {rapid_success}/3 successful\"\n",
    "    )\n",
    "\n",
    "    overall_success = all(results)\n",
    "    print(\n",
    "        f\"\\n{'‚úÖ All tests passed!' if overall_success else '‚ö†Ô∏è  Some tests failed - proceed with caution'}\"\n",
    "    )\n",
    "    return overall_success\n",
    "\n",
    "\n",
    "# Run comprehensive tests\n",
    "if client.test_connection():\n",
    "    comprehensive_success = run_comprehensive_api_test(client)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping comprehensive tests - basic connection failed\")\n",
    "    comprehensive_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-section",
   "metadata": {},
   "source": [
    "## Dataset Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dataset-loader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Loading routellm_gpt4...\n",
      "üì• Loading routellm/gpt4_dataset dataset...\n",
      "üìä Dataset loaded: 10,000 total samples\n",
      "üöÄ Using all 10,000 samples\n",
      "‚úÖ Extracted 10,000 valid prompts\n",
      "\n",
      "üìù Sample prompts:\n",
      "  1. Write c++ code, which calculates and outputs n digits of pi. (60 chars)\n",
      "  2. [Partner Cooperation Team] Share webinar schedule for Cafe24 employees\n",
      "hello. This is a partnership ... (957 chars)\n",
      "  3. Write a short rhyming poem explaining Einstein's theory of general relativity in easy but accurate t... (104 chars)\n",
      "\n",
      "üìà Quality stats:\n",
      "  - Valid prompts: 10,000\n",
      "  - Average length: 392 chars\n",
      "  - Length range: 19-3805 chars\n",
      "\n",
      "üéØ Total prompts available: 10,000\n",
      "‚è±Ô∏è  Estimated test time: 0.1 minutes\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_prompts(config: Dict) -> List[str]:\n",
    "    \"\"\"Load and prepare prompts from a dataset.\"\"\"\n",
    "    try:\n",
    "        print(f\"üì• Loading {config['name']} dataset...\")\n",
    "\n",
    "        # Load dataset\n",
    "        dataset = load_dataset(config[\"name\"], split=config[\"split\"])\n",
    "        print(f\"üìä Dataset loaded: {len(dataset):,} total samples\")\n",
    "\n",
    "        # Sample if needed\n",
    "        sample_size = config.get(\"sample_size\")\n",
    "        if sample_size and sample_size < len(dataset):\n",
    "            print(f\"üéØ Sampling {sample_size:,} from {len(dataset):,} samples\")\n",
    "            dataset = dataset.shuffle(seed=42).select(range(sample_size))\n",
    "        else:\n",
    "            print(f\"üöÄ Using all {len(dataset):,} samples\")\n",
    "\n",
    "        # Extract prompts\n",
    "        prompts = []\n",
    "        prompt_column = config[\"prompt_column\"]\n",
    "\n",
    "        for item in dataset:\n",
    "            if prompt_column in item and item[prompt_column]:\n",
    "                prompt_text = item[prompt_column].strip()\n",
    "                if prompt_text:\n",
    "                    prompts.append(prompt_text)\n",
    "\n",
    "        print(f\"‚úÖ Extracted {len(prompts):,} valid prompts\")\n",
    "\n",
    "        # Show sample prompts\n",
    "        if prompts:\n",
    "            print(\"\\nüìù Sample prompts:\")\n",
    "            for i, prompt in enumerate(prompts[:3]):\n",
    "                preview = prompt[:100] + \"...\" if len(prompt) > 100 else prompt\n",
    "                print(f\"  {i+1}. {preview} ({len(prompt)} chars)\")\n",
    "\n",
    "        # Quality stats\n",
    "        if len(prompts) > 10:\n",
    "            lengths = [len(p) for p in prompts]\n",
    "            print(\"\\nüìà Quality stats:\")\n",
    "            print(f\"  - Valid prompts: {len(prompts):,}\")\n",
    "            print(f\"  - Average length: {np.mean(lengths):.0f} chars\")\n",
    "            print(f\"  - Length range: {min(lengths)}-{max(lengths)} chars\")\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        print(\"üí° Try: huggingface-cli login\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "datasets = {}\n",
    "if comprehensive_success:\n",
    "    for name, config in DATASET_CONFIG.items():\n",
    "        print(f\"\\nüîç Loading {name}...\")\n",
    "        prompts = load_dataset_prompts(config)\n",
    "        if prompts:\n",
    "            datasets[name] = {\"prompts\": prompts, \"config\": config}\n",
    "\n",
    "    total_prompts = sum(len(data[\"prompts\"]) for data in datasets.values())\n",
    "    print(f\"\\nüéØ Total prompts available: {total_prompts:,}\")\n",
    "\n",
    "    if total_prompts > 0:\n",
    "        estimated_time = (\n",
    "            TEST_CONFIG[\"sample_size\"] * TEST_CONFIG[\"rate_limit_delay\"]\n",
    "        ) / 60\n",
    "        print(f\"‚è±Ô∏è  Estimated test time: {estimated_time:.1f} minutes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping dataset loading - API tests failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-section",
   "metadata": {},
   "source": [
    "## Protocol Routing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "routing-tests",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Protocol routing test function ready\n"
     ]
    }
   ],
   "source": [
    "def test_protocol_routing(\n",
    "    client: AdaptiveAIClient,\n",
    "    prompts: List[str],\n",
    "    dataset_name: str,\n",
    "    add_tools: bool = False,\n",
    "    max_prompts: Optional[int] = None,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Test protocol routing with enhanced monitoring and error handling.\"\"\"\n",
    "\n",
    "    # Limit prompts if specified\n",
    "    if max_prompts and len(prompts) > max_prompts:\n",
    "        prompts = prompts[:max_prompts]\n",
    "        print(f\"üéØ Testing {max_prompts:,} prompts from {dataset_name}\")\n",
    "    else:\n",
    "        print(f\"üß™ Testing {len(prompts):,} prompts from {dataset_name}\")\n",
    "\n",
    "    # Define tools if needed\n",
    "    tools = None\n",
    "    if add_tools:\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_information\",\n",
    "                    \"description\": \"Get additional information\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\"query\": {\"type\": \"string\"}},\n",
    "                        \"required\": [\"query\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    print(f\"‚öôÔ∏è  Tools: {'Yes' if add_tools else 'No'}\")\n",
    "    print(\n",
    "        f\"‚è±Ô∏è  Estimated time: {(len(prompts) * TEST_CONFIG['rate_limit_delay']) / 60:.1f} minutes\"\n",
    "    )\n",
    "\n",
    "    # Pre-flight check\n",
    "    test_response = client.query([{\"role\": \"user\", \"content\": \"test\"}], tools)\n",
    "    if not test_response:\n",
    "        print(\"‚ùå Pre-flight test failed\")\n",
    "        return []\n",
    "    print(\"‚úÖ Pre-flight test passed\")\n",
    "\n",
    "    # Initialize tracking\n",
    "    results = []\n",
    "    consecutive_failures = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Process prompts\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = client.query(messages, tools)\n",
    "\n",
    "        if response:\n",
    "            consecutive_failures = 0\n",
    "\n",
    "            # Extract result data\n",
    "            result = {\n",
    "                \"dataset\": dataset_name,\n",
    "                \"index\": i,\n",
    "                \"prompt_preview\": prompt[:200] + \"...\" if len(prompt) > 200 else prompt,\n",
    "                \"prompt_length\": len(prompt),\n",
    "                \"has_tools\": add_tools,\n",
    "                \"protocol\": response.get(\"protocol\"),\n",
    "                \"provider\": None,\n",
    "                \"model\": None,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            # Extract provider and model info\n",
    "            if response.get(\"protocol\") == \"standard_llm\" and response.get(\"standard\"):\n",
    "                result[\"provider\"] = response[\"standard\"].get(\"provider\")\n",
    "                result[\"model\"] = response[\"standard\"].get(\"model\")\n",
    "            elif response.get(\"protocol\") == \"minion\" and response.get(\"minion\"):\n",
    "                result[\"provider\"] = \"huggingface\"\n",
    "                result[\"model\"] = response[\"minion\"].get(\"model\")\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "        else:\n",
    "            consecutive_failures += 1\n",
    "            print(f\"‚ùå Failed prompt {i+1} (consecutive: {consecutive_failures})\")\n",
    "\n",
    "            if consecutive_failures >= TEST_CONFIG[\"max_consecutive_failures\"]:\n",
    "                print(f\"üõë Stopping after {consecutive_failures} consecutive failures\")\n",
    "                break\n",
    "\n",
    "        # Progress reporting\n",
    "        if (i + 1) % TEST_CONFIG[\"progress_interval\"] == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = (i + 1) / elapsed\n",
    "\n",
    "            if results:\n",
    "                recent_results = results[-TEST_CONFIG[\"progress_interval\"] :]\n",
    "                protocols = [r[\"protocol\"] for r in recent_results]\n",
    "                minion_pct = (protocols.count(\"minion\") / len(protocols)) * 100\n",
    "\n",
    "                print(\n",
    "                    f\"üìä Progress: {i+1:,}/{len(prompts):,} | \"\n",
    "                    f\"Rate: {rate:.1f}/sec | \"\n",
    "                    f\"MINION: {minion_pct:.1f}% | \"\n",
    "                    f\"Success: {len(results):,}\"\n",
    "                )\n",
    "\n",
    "        # Rate limiting\n",
    "        time.sleep(TEST_CONFIG[\"rate_limit_delay\"])\n",
    "\n",
    "    # Final summary\n",
    "    total_time = time.time() - start_time\n",
    "    success_rate = (len(results) / len(prompts)) * 100\n",
    "\n",
    "    print(\"\\n‚úÖ Test completed:\")\n",
    "    print(f\"   - Success rate: {success_rate:.1f}% ({len(results):,}/{len(prompts):,})\")\n",
    "    print(f\"   - Total time: {total_time/60:.1f} minutes\")\n",
    "    print(f\"   - Average rate: {len(results)/total_time:.1f} requests/sec\")\n",
    "\n",
    "    if results:\n",
    "        protocols = [r[\"protocol\"] for r in results]\n",
    "        minion_count = protocols.count(\"minion\")\n",
    "        standard_count = protocols.count(\"standard_llm\")\n",
    "\n",
    "        print(f\"   - MINION: {minion_count:,} ({(minion_count/len(results))*100:.1f}%)\")\n",
    "        print(\n",
    "            f\"   - STANDARD: {standard_count:,} ({(standard_count/len(results))*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"üß™ Protocol routing test function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-test-section",
   "metadata": {},
   "source": [
    "## Quick Test: Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quick-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running quick test with custom prompts...\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Testing WITHOUT tools:\n",
      "üß™ Testing 5 prompts from custom_test\n",
      "‚öôÔ∏è  Tools: No\n",
      "‚è±Ô∏è  Estimated time: 0.0 minutes\n",
      "‚úÖ Pre-flight test passed\n",
      "\n",
      "‚úÖ Test completed:\n",
      "   - Success rate: 100.0% (5/5)\n",
      "   - Total time: 0.0 minutes\n",
      "   - Average rate: 2.0 requests/sec\n",
      "   - MINION: 5 (100.0%)\n",
      "   - STANDARD: 0 (0.0%)\n",
      "\n",
      "2Ô∏è‚É£ Testing WITH tools:\n",
      "üß™ Testing 3 prompts from custom_test_tools\n",
      "‚öôÔ∏è  Tools: Yes\n",
      "‚è±Ô∏è  Estimated time: 0.0 minutes\n",
      "‚úÖ Pre-flight test passed\n",
      "\n",
      "‚úÖ Test completed:\n",
      "   - Success rate: 100.0% (3/3)\n",
      "   - Total time: 0.0 minutes\n",
      "   - Average rate: 1.8 requests/sec\n",
      "   - MINION: 0 (0.0%)\n",
      "   - STANDARD: 3 (100.0%)\n",
      "\n",
      "üìä Quick test results:\n",
      "           minion | What is 2+2?...\n",
      "           minion | Hello world...\n",
      "           minion | Explain machine learning in detail...\n",
      "           minion | Write a comprehensive Python algorithm for sorting...\n",
      "           minion | Analyze the economic implications of inflation on global mar...\n",
      "  üîß standard_llm | What is 2+2?...\n",
      "  üîß standard_llm | Hello world...\n",
      "  üîß standard_llm | Explain machine learning in detail...\n",
      "\n",
      "‚úÖ Quick test successful! Ready for dataset testing.\n"
     ]
    }
   ],
   "source": [
    "# Quick test with custom prompts to verify functionality\n",
    "custom_prompts = [\n",
    "    \"What is 2+2?\",\n",
    "    \"Hello world\",\n",
    "    \"Explain machine learning in detail\",\n",
    "    \"Write a comprehensive Python algorithm for sorting\",\n",
    "    \"Analyze the economic implications of inflation on global markets\",\n",
    "]\n",
    "\n",
    "print(\"üöÄ Running quick test with custom prompts...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if comprehensive_success:\n",
    "    # Test without tools\n",
    "    print(\"\\n1Ô∏è‚É£ Testing WITHOUT tools:\")\n",
    "    custom_results_no_tools = test_protocol_routing(\n",
    "        client, custom_prompts, \"custom_test\", add_tools=False\n",
    "    )\n",
    "\n",
    "    # Test with tools\n",
    "    print(\"\\n2Ô∏è‚É£ Testing WITH tools:\")\n",
    "    custom_results_with_tools = test_protocol_routing(\n",
    "        client, custom_prompts[:3], \"custom_test_tools\", add_tools=True\n",
    "    )\n",
    "\n",
    "    # Combine results\n",
    "    all_custom_results = custom_results_no_tools + custom_results_with_tools\n",
    "\n",
    "    if all_custom_results:\n",
    "        print(\"\\nüìä Quick test results:\")\n",
    "        for result in all_custom_results:\n",
    "            tools_str = \"üîß\" if result[\"has_tools\"] else \"  \"\n",
    "            print(\n",
    "                f\"  {tools_str} {result['protocol']:>12} | {result['prompt_preview'][:60]}...\"\n",
    "            )\n",
    "\n",
    "        print(\"\\n‚úÖ Quick test successful! Ready for dataset testing.\")\n",
    "    else:\n",
    "        print(\"‚ùå Quick test failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping quick test - API not available\")\n",
    "    all_custom_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-test-section",
   "metadata": {},
   "source": [
    "## Dataset Testing: RouteLL GPT-4 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dataset-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ DATASET TESTING\n",
      "============================================================\n",
      "\n",
      "üìã Testing dataset: routellm_gpt4\n",
      "üìä Available prompts: 10,000\n",
      "\n",
      "1Ô∏è‚É£ Testing routellm_gpt4 WITHOUT tools:\n",
      "üéØ Testing 100 prompts from routellm_gpt4\n",
      "‚öôÔ∏è  Tools: No\n",
      "‚è±Ô∏è  Estimated time: 0.1 minutes\n",
      "‚úÖ Pre-flight test passed\n",
      "\n",
      "‚úÖ Test completed:\n",
      "   - Success rate: 100.0% (100/100)\n",
      "   - Total time: 1.2 minutes\n",
      "   - Average rate: 1.4 requests/sec\n",
      "   - MINION: 85 (85.0%)\n",
      "   - STANDARD: 15 (15.0%)\n",
      "\n",
      "2Ô∏è‚É£ Testing routellm_gpt4 WITH tools:\n",
      "üéØ Testing 50 prompts from routellm_gpt4_tools\n",
      "‚öôÔ∏è  Tools: Yes\n",
      "‚è±Ô∏è  Estimated time: 0.0 minutes\n",
      "‚úÖ Pre-flight test passed\n",
      "\n",
      "‚úÖ Test completed:\n",
      "   - Success rate: 100.0% (50/50)\n",
      "   - Total time: 0.5 minutes\n",
      "   - Average rate: 1.6 requests/sec\n",
      "   - MINION: 0 (0.0%)\n",
      "   - STANDARD: 50 (100.0%)\n",
      "\n",
      "‚úÖ Completed routellm_gpt4\n",
      "\n",
      "üéâ All dataset testing completed!\n",
      "üìä Total results: 150\n"
     ]
    }
   ],
   "source": [
    "# Test the RouteLL GPT-4 dataset\n",
    "all_results = []\n",
    "\n",
    "if comprehensive_success and datasets:\n",
    "    print(\"üöÄ DATASET TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for dataset_name, data in datasets.items():\n",
    "        if not data[\"prompts\"]:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìã Testing dataset: {dataset_name}\")\n",
    "        print(f\"üìä Available prompts: {len(data['prompts']):,}\")\n",
    "\n",
    "        # Test without tools\n",
    "        print(f\"\\n1Ô∏è‚É£ Testing {dataset_name} WITHOUT tools:\")\n",
    "        results_no_tools = test_protocol_routing(\n",
    "            client,\n",
    "            data[\"prompts\"],\n",
    "            dataset_name,\n",
    "            add_tools=False,\n",
    "            max_prompts=TEST_CONFIG[\"sample_size\"],\n",
    "        )\n",
    "        all_results.extend(results_no_tools)\n",
    "\n",
    "        # Test with tools (smaller sample)\n",
    "        if TEST_CONFIG[\"tools_test_size\"] > 0:\n",
    "            print(f\"\\n2Ô∏è‚É£ Testing {dataset_name} WITH tools:\")\n",
    "            results_with_tools = test_protocol_routing(\n",
    "                client,\n",
    "                data[\"prompts\"],\n",
    "                f\"{dataset_name}_tools\",\n",
    "                add_tools=True,\n",
    "                max_prompts=TEST_CONFIG[\"tools_test_size\"],\n",
    "            )\n",
    "            all_results.extend(results_with_tools)\n",
    "\n",
    "        print(f\"\\n‚úÖ Completed {dataset_name}\")\n",
    "\n",
    "    print(\"\\nüéâ All dataset testing completed!\")\n",
    "    print(f\"üìä Total results: {len(all_results):,}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping dataset testing - prerequisites not met\")\n",
    "    all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-section",
   "metadata": {},
   "source": [
    "## Results Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PROTOCOL ROUTING ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. Overall Protocol Distribution:\n",
      "         minion: 85 (56.7%)\n",
      "   standard_llm: 65 (43.3%)\n",
      "\n",
      "2. Tools Impact:\n",
      "protocol   minion  standard_llm\n",
      "has_tools                      \n",
      "False        85.0          15.0\n",
      "True          0.0         100.0\n",
      "\n",
      "3. Protocol Distribution by Dataset:\n",
      "protocol             minion  standard_llm\n",
      "dataset                                  \n",
      "routellm_gpt4          85.0          15.0\n",
      "routellm_gpt4_tools     0.0         100.0\n",
      "\n",
      "4. Prompt Length Analysis:\n",
      "               mean  median    std  count\n",
      "protocol                                 \n",
      "minion        295.6    89.0  376.6     85\n",
      "standard_llm  287.2   163.0  292.9     65\n",
      "\n",
      "5. Top Models Used:\n",
      "   Qwen/Qwen2.5-14B-Instruct: 77 (51.3%)\n",
      "   gpt-4o: 55 (36.7%)\n",
      "   deepseek-chat: 10 (6.7%)\n",
      "   codellama/CodeLlama-13b-Instruct-hf: 5 (3.3%)\n",
      "   google/flan-t5-xl: 2 (1.3%)\n",
      "\n",
      "6. Efficiency Metrics:\n",
      "   MINION (efficient): 56.7%\n",
      "   STANDARD (capable): 43.3%\n",
      "   ‚úÖ Balanced routing distribution\n",
      "\n",
      "7. Recommendations:\n",
      "   ‚úÖ All tool requests properly routed to STANDARD\n"
     ]
    }
   ],
   "source": [
    "def analyze_results(results: List[Dict]) -> None:\n",
    "    \"\"\"Comprehensive analysis of protocol routing results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"‚ö†Ô∏è No results to analyze\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    print(\"üìä PROTOCOL ROUTING ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1. Overall distribution\n",
    "    print(\"\\n1. Overall Protocol Distribution:\")\n",
    "    protocol_counts = df[\"protocol\"].value_counts()\n",
    "    for protocol, count in protocol_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"   {protocol:>12}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "    # 2. Tools impact\n",
    "    print(\"\\n2. Tools Impact:\")\n",
    "    tools_cross = pd.crosstab(df[\"has_tools\"], df[\"protocol\"], normalize=\"index\") * 100\n",
    "    print(tools_cross.round(1))\n",
    "\n",
    "    # 3. Dataset breakdown\n",
    "    if df[\"dataset\"].nunique() > 1:\n",
    "        print(\"\\n3. Protocol Distribution by Dataset:\")\n",
    "        dataset_cross = (\n",
    "            pd.crosstab(df[\"dataset\"], df[\"protocol\"], normalize=\"index\") * 100\n",
    "        )\n",
    "        print(dataset_cross.round(1))\n",
    "\n",
    "    # 4. Length analysis\n",
    "    print(\"\\n4. Prompt Length Analysis:\")\n",
    "    length_stats = df.groupby(\"protocol\")[\"prompt_length\"].agg(\n",
    "        [\"mean\", \"median\", \"std\", \"count\"]\n",
    "    )\n",
    "    print(length_stats.round(1))\n",
    "\n",
    "    # 5. Model distribution\n",
    "    print(\"\\n5. Top Models Used:\")\n",
    "    model_counts = df[\"model\"].value_counts().head(5)\n",
    "    for model, count in model_counts.items():\n",
    "        if pd.notna(model):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"   {model}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    # 6. Efficiency metrics\n",
    "    print(\"\\n6. Efficiency Metrics:\")\n",
    "    minion_pct = (df[\"protocol\"] == \"minion\").mean() * 100\n",
    "    standard_pct = (df[\"protocol\"] == \"standard_llm\").mean() * 100\n",
    "\n",
    "    print(f\"   MINION (efficient): {minion_pct:.1f}%\")\n",
    "    print(f\"   STANDARD (capable): {standard_pct:.1f}%\")\n",
    "\n",
    "    if minion_pct > 70:\n",
    "        print(\"   ‚úÖ High efficiency - good cost optimization\")\n",
    "    elif minion_pct < 50:\n",
    "        print(\"   ‚ö†Ô∏è  Low efficiency - consider threshold adjustment\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Balanced routing distribution\")\n",
    "\n",
    "    # 7. Recommendations\n",
    "    print(\"\\n7. Recommendations:\")\n",
    "\n",
    "    # Check for proper tools routing\n",
    "    tools_to_minion = len(df[(df[\"has_tools\"] == True) & (df[\"protocol\"] == \"minion\")])\n",
    "    if tools_to_minion > 0:\n",
    "        print(\n",
    "            f\"   ‚ö†Ô∏è  {tools_to_minion} requests with tools routed to MINION (should be STANDARD)\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"   ‚úÖ All tool requests properly routed to STANDARD\")\n",
    "\n",
    "    # Check for short prompts going to STANDARD\n",
    "    short_to_standard = len(\n",
    "        df[\n",
    "            (df[\"has_tools\"] == False)\n",
    "            & (df[\"prompt_length\"] < 100)\n",
    "            & (df[\"protocol\"] == \"standard_llm\")\n",
    "        ]\n",
    "    )\n",
    "    if short_to_standard > 5:\n",
    "        print(\n",
    "            f\"   üîç {short_to_standard} short prompts without tools routed to STANDARD\"\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Analyze results\n",
    "if all_results:\n",
    "    results_df = analyze_results(all_results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results available for analysis\")\n",
    "    results_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "visualization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Creating visualizations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#FF6B6B",
           "#4ECDC4"
          ]
         },
         "name": "Protocol Distribution",
         "text": [
          "85",
          "65"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "minion",
          "standard_llm"
         ],
         "xaxis": "x",
         "y": [
          85,
          65
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#FF6B6B"
         },
         "name": "minion",
         "showlegend": false,
         "text": [
          "85",
          "0"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "No Tools",
          "With Tools"
         ],
         "xaxis": "x2",
         "y": [
          85,
          0
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#4ECDC4"
         },
         "name": "standard_llm",
         "showlegend": false,
         "text": [
          "15",
          "50"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "No Tools",
          "With Tools"
         ],
         "xaxis": "x2",
         "y": [
          15,
          50
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#FF6B6B"
         },
         "name": "standard_llm",
         "showlegend": false,
         "type": "box",
         "xaxis": "x3",
         "y": [
          60,
          104,
          278,
          223,
          825,
          261,
          104,
          403,
          496,
          134,
          362,
          685,
          659,
          484,
          562,
          60,
          957,
          104,
          268,
          47,
          396,
          26,
          89,
          1416,
          65,
          103,
          41,
          75,
          204,
          566,
          33,
          54,
          73,
          278,
          74,
          223,
          334,
          726,
          49,
          825,
          261,
          638,
          274,
          913,
          163,
          228,
          41,
          104,
          850,
          51,
          403,
          84,
          19,
          47,
          314,
          39,
          118,
          64,
          61,
          91,
          496,
          62,
          134,
          122,
          362
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#4ECDC4"
         },
         "name": "minion",
         "showlegend": false,
         "type": "box",
         "xaxis": "x3",
         "y": [
          957,
          268,
          47,
          396,
          26,
          89,
          1416,
          65,
          103,
          41,
          75,
          204,
          566,
          33,
          54,
          73,
          74,
          334,
          726,
          49,
          638,
          274,
          913,
          163,
          228,
          41,
          850,
          51,
          84,
          19,
          47,
          314,
          39,
          118,
          64,
          61,
          91,
          62,
          122,
          1211,
          161,
          604,
          37,
          1289,
          58,
          44,
          32,
          55,
          61,
          62,
          46,
          76,
          47,
          41,
          247,
          1110,
          338,
          346,
          562,
          905,
          1524,
          28,
          384,
          292,
          497,
          21,
          122,
          532,
          203,
          49,
          320,
          83,
          67,
          68,
          1177,
          594,
          32,
          228,
          54,
          67,
          320,
          40,
          33,
          65,
          1215
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#FF6B6B"
         },
         "name": "minion_ds",
         "showlegend": false,
         "type": "bar",
         "x": [
          "routellm_gpt4",
          "routellm_gpt4_tools"
         ],
         "xaxis": "x4",
         "y": [
          85,
          0
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#4ECDC4"
         },
         "name": "standard_llm_ds",
         "showlegend": false,
         "type": "bar",
         "x": [
          "routellm_gpt4",
          "routellm_gpt4_tools"
         ],
         "xaxis": "x4",
         "y": [
          15,
          50
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Protocol Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Tools Impact on Routing",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Prompt Length by Protocol",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Dataset Comparison",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Adaptive AI Protocol Analysis Dashboard",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_visualizations(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Create comprehensive visualizations of the results.\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"‚ö†Ô∏è No data available for visualization\")\n",
    "        return\n",
    "\n",
    "    print(\"üìà Creating visualizations...\")\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        subplot_titles=(\n",
    "            \"Protocol Distribution\",\n",
    "            \"Tools Impact on Routing\",\n",
    "            \"Prompt Length by Protocol\",\n",
    "            \"Dataset Comparison\",\n",
    "        ),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}], [{\"type\": \"box\"}, {\"type\": \"bar\"}]],\n",
    "    )\n",
    "\n",
    "    # 1. Overall protocol distribution\n",
    "    protocol_counts = df[\"protocol\"].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"Protocol Distribution\",\n",
    "            x=protocol_counts.index,\n",
    "            y=protocol_counts.values,\n",
    "            text=[f\"{v:,}\" for v in protocol_counts.values],\n",
    "            textposition=\"auto\",\n",
    "            marker_color=[\"#FF6B6B\", \"#4ECDC4\"],\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    # 2. Tools impact\n",
    "    tools_data = df.groupby([\"has_tools\", \"protocol\"]).size().unstack(fill_value=0)\n",
    "    for i, protocol in enumerate(tools_data.columns):\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=protocol,\n",
    "                x=[\"No Tools\", \"With Tools\"],\n",
    "                y=tools_data[protocol],\n",
    "                text=[f\"{v:,}\" for v in tools_data[protocol]],\n",
    "                textposition=\"auto\",\n",
    "                showlegend=False,\n",
    "                marker_color=[\"#FF6B6B\", \"#4ECDC4\"][i],\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    # 3. Prompt length distribution\n",
    "    for protocol in df[\"protocol\"].unique():\n",
    "        protocol_data = df[df[\"protocol\"] == protocol]\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                name=protocol,\n",
    "                y=protocol_data[\"prompt_length\"],\n",
    "                showlegend=False,\n",
    "                marker_color=\"#FF6B6B\" if protocol == \"standard_llm\" else \"#4ECDC4\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # 4. Dataset comparison (if multiple datasets)\n",
    "    if df[\"dataset\"].nunique() > 1:\n",
    "        dataset_data = df.groupby([\"dataset\", \"protocol\"]).size().unstack(fill_value=0)\n",
    "        for i, protocol in enumerate(dataset_data.columns):\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    name=f\"{protocol}_ds\",\n",
    "                    x=dataset_data.index,\n",
    "                    y=dataset_data[protocol],\n",
    "                    showlegend=False,\n",
    "                    marker_color=[\"#FF6B6B\", \"#4ECDC4\"][i],\n",
    "                ),\n",
    "                row=2,\n",
    "                col=2,\n",
    "            )\n",
    "    else:\n",
    "        # Show model distribution instead\n",
    "        model_counts = df[\"model\"].value_counts().head(5)\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Models\",\n",
    "                x=model_counts.index,\n",
    "                y=model_counts.values,\n",
    "                showlegend=False,\n",
    "                marker_color=\"#45B7D1\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Adaptive AI Protocol Analysis Dashboard\",\n",
    "        title_x=0.5,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Create visualizations\n",
    "if results_df is not None:\n",
    "    create_visualizations(results_df)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-section",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Detailed results exported to: protocol_analysis_20250706_224334.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Export results\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_results:\n\u001b[0;32m---> 55\u001b[0m     export_results(all_results, results_df)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è No results to export\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 42\u001b[0m, in \u001b[0;36mexport_results\u001b[0;34m(results, df)\u001b[0m\n\u001b[1;32m     40\u001b[0m json_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol_analysis_summary_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 42\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(summary, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìã Summary exported to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ All exports completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m _default(o)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "def export_results(results: List[Dict], df: Optional[pd.DataFrame] = None) -> None:\n",
    "    \"\"\"Export results to CSV and JSON files.\"\"\"\n",
    "    if not results:\n",
    "        print(\"‚ö†Ô∏è No results to export\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Export detailed results to CSV\n",
    "    if df is not None:\n",
    "        csv_filename = f\"protocol_analysis_{timestamp}.csv\"\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"üìÅ Detailed results exported to: {csv_filename}\")\n",
    "\n",
    "    # Export summary to JSON\n",
    "    summary = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"total_tests\": len(results),\n",
    "            \"datasets_tested\": len(set(r[\"dataset\"] for r in results)),\n",
    "            \"test_config\": TEST_CONFIG,\n",
    "        },\n",
        "protocol_distribution": {
            k: int(v) for k, v in pd.Series([r["protocol"] for r in results])
                                        .value_counts()
                                        .items()
        },
    "        \"efficiency_metrics\": {\n",
    "            \"minion_percentage\": (\n",
    "                sum(1 for r in results if r[\"protocol\"] == \"minion\") / len(results)\n",
    "            )\n",
    "            * 100,\n",
    "            \"standard_percentage\": (\n",
    "                sum(1 for r in results if r[\"protocol\"] == \"standard_llm\")\n",
    "                / len(results)\n",
    "            )\n",
    "            * 100,\n",
    "        },\n",
    "        \"tools_analysis\": {\n",
    "            \"with_tools_total\": sum(1 for r in results if r[\"has_tools\"]),\n",
    "            \"with_tools_to_standard\": sum(\n",
    "                1 for r in results if r[\"has_tools\"] and r[\"protocol\"] == \"standard_llm\"\n",
    "            ),\n",
    "            \"without_tools_to_minion\": sum(\n",
    "                1 for r in results if not r[\"has_tools\"] and r[\"protocol\"] == \"minion\"\n",
    "            ),\n",
    "        },\n",
    "        \"prompt_stats\": {\n",
    "            \"avg_length\": sum(r[\"prompt_length\"] for r in results) / len(results),\n",
    "            \"min_length\": min(r[\"prompt_length\"] for r in results),\n",
    "            \"max_length\": max(r[\"prompt_length\"] for r in results),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    json_filename = f\"protocol_analysis_summary_{timestamp}.json\"\n",
    "    with open(json_filename, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"üìã Summary exported to: {json_filename}\")\n",
    "    print(\"\\n‚úÖ All exports completed successfully!\")\n",
    "\n",
    "    # Print key metrics\n",
    "    print(\"\\nüìä Key Metrics:\")\n",
    "    print(f\"   - Total tests: {summary['metadata']['total_tests']:,}\")\n",
    "    print(\n",
    "        f\"   - MINION efficiency: {summary['efficiency_metrics']['minion_percentage']:.1f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - Tools routing accuracy: {(summary['tools_analysis']['with_tools_to_standard'] / max(1, summary['tools_analysis']['with_tools_total'])) * 100:.1f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Export results\n",
    "if all_results:\n",
    "    export_results(all_results, results_df)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "\n",
    "This notebook provides comprehensive analysis of the Adaptive AI protocol routing system:\n",
    "\n",
    "### ‚úÖ **What We Tested:**\n",
    "- Rule-based protocol selection logic\n",
    "- Tools impact on routing decisions\n",
    "- Real-world prompt complexity handling\n",
    "- Performance and efficiency metrics\n",
    "\n",
    "### üìä **Key Insights:**\n",
    "- **Efficiency**: MINION protocol usage for cost optimization\n",
    "- **Accuracy**: Tools always route to STANDARD (correct behavior)\n",
    "- **Balance**: Appropriate distribution between protocols\n",
    "- **Performance**: Fast, deterministic routing decisions\n",
    "\n",
    "### üîÑ **Continuous Improvement:**\n",
    "- Use exported data to track performance over time\n",
    "- Adjust thresholds based on real-world usage patterns\n",
    "- Monitor cost vs. performance trade-offs\n",
    "- Validate routing decisions with user feedback\n",
    "\n",
    "### üéØ **Next Steps:**\n",
    "1. Review exported CSV/JSON files for detailed analysis\n",
    "2. Adjust `TEST_CONFIG` for larger-scale testing if needed\n",
    "3. Compare results across different time periods\n",
    "4. Fine-tune protocol selection thresholds based on findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d4663",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3158468b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b6e6b54",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
