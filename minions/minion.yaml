properties:
  environmentId: ${ENVIRONMENT_ID}
  workloadProfileName: ${WORKLOAD_PROFILE}
  configuration:
    activeRevisionsMode: Single
    secrets:
      - name: hf-token
        value: ${HF_TOKEN}
    ingress:
      external: false
      allowInsecure: false
      targetPort: 8000
      traffic:
        - latestRevision: true
          weight: 100
      transport: Auto
  template:
    containers:
      - image: ${CONTAINER_IMAGE}
        name: vllm
        env:
          - name: HF_TOKEN
            secretRef: hf-token
        args:
          - "--model"
          - "${MODEL_ID}"
          - "--port"
          - "8000"
          - "--host"
          - "0.0.0.0"
          - "--gpu-memory-utilization"
          - "0.9"
          - "--max-model-len"
          - "${MAX_MODEL_LEN}"
          - "--served-model-name"
          - "${MODEL_ID}"
          - "--max-num-seqs"
          - "256"
          - "--tensor-parallel-size"
          - "1"
          - "--dtype"
          - "auto"
          - "--enable-prefix-caching"
        volumeMounts:
          - mountPath: /root/.cache/huggingface
            volumeName: model-cache
        resources:
          cpu: 4.0
          memory: 32Gi
        probes:
          - type: liveness
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
    scale:
      minReplicas: 0
      maxReplicas: 1
    volumes:
      - name: model-cache
        storageType: AzureFile
        storageName: ${STORAGE_NAME}
