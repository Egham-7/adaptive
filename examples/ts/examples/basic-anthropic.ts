/**
 * Basic Anthropic SDK Example
 *
 * This example demonstrates how to use Adaptive with Anthropic's Messages API
 * format while getting intelligent model routing and cost optimization.
 *
 * Features demonstrated:
 * - Anthropic Messages API compatibility
 * - Both streaming and non-streaming responses
 * - Intelligent model routing (empty model string)
 * - Automatic cost optimization and provider selection
 * - Proper TypeScript typing for Claude responses
 *
 * Key benefits:
 * - Keep using familiar Anthropic SDK patterns
 * - Get cost savings through intelligent routing
 * - Automatic fallback between providers
 * - Native Claude response format preserved
 *
 * Set ADAPTIVE_API_KEY environment variable to avoid hardcoding your API key.
 */

import Anthropic from "@anthropic-ai/sdk";

// Initialize the Anthropic client with Adaptive's endpoint
// This allows you to use Claude's Messages API while getting intelligent routing
const client = new Anthropic({
  apiKey: process.env.ADAPTIVE_API_KEY || "your-adaptive-api-key",
  baseURL: "https://llmadaptive.com/api", // Adaptive's endpoint
});

// Type definitions for better TypeScript support
interface AdaptiveAnthropicResponse extends Anthropic.Message {
  provider?: string;
}

// Non-streaming example - get complete response at once
async function nonStreamingExample() {
  console.log("=== Non-Streaming Anthropic Example ===");
  console.log("ğŸ’¬ Sending message: 'Hello!'");
  console.log("ğŸ§  Using intelligent routing (empty model string)...");
  console.log("â³ Waiting for complete response...");

  try {
    const response = (await client.messages.create({
      model: "", // Leave empty for intelligent routing - Adaptive chooses the best model
      max_tokens: 1000,
      messages: [{ role: "user", content: "Hello!" }],
      stream: false, // Explicitly disable streaming
    })) as AdaptiveAnthropicResponse;

    // Type-safe response handling for Anthropic's format
    const firstContent = response.content[0];
    if (!firstContent || firstContent.type !== "text") {
      console.log("âŒ No text response content received");
      return;
    }

    // Display the response with provider information
    console.log();
    console.log("âœ… Response received:");
    console.log("ğŸ“ Content:", firstContent.text);

    // Adaptive adds provider information to the response
    if (response.provider) {
      console.log("ğŸ¢ Provider used:", response.provider);
    }
    // Model information is part of Anthropic's standard response
    console.log("ğŸ¤– Model used:", response.model);

    // Usage information (Anthropic format)
    if (response.usage) {
      console.log("ğŸ“Š Usage:");
      console.log(`   â€¢ Input tokens: ${response.usage.input_tokens}`);
      console.log(`   â€¢ Output tokens: ${response.usage.output_tokens}`);
      console.log(
        `   â€¢ Total tokens: ${response.usage.input_tokens + response.usage.output_tokens}`,
      );
    }

    console.log("ğŸ” Response metadata:");
    console.log(`   â€¢ ID: ${response.id}`);
    console.log(`   â€¢ Role: ${response.role}`);
    console.log(`   â€¢ Stop reason: ${response.stop_reason}`);

    console.log();
    console.log("âœ¨ Non-streaming example completed successfully!");
  } catch (error) {
    console.error("âŒ Non-streaming Error:", error);

    if (error instanceof Anthropic.APIError) {
      console.error("ğŸ”§ API Error Details:");
      console.error("   â€¢ Status:", error.status);
      console.error("   â€¢ Message:", error.message);
      if (error.error) {
        console.error("   â€¢ Error type:", error.error.type);
      }
    }

    throw error;
  }
}

// Streaming example - get response as it's generated
async function streamingExample() {
  console.log("=== Streaming Anthropic Example ===");
  console.log(
    "ğŸ’¬ Sending message: 'Write a short story about a robot learning to paint'",
  );
  console.log("ğŸ§  Using intelligent routing with streaming...");
  console.log("ğŸ“¡ Response will appear in real-time:");
  console.log();

  try {
    const stream = client.messages.stream({
      model: "", // Leave empty for intelligent routing
      max_tokens: 200, // Limit response length for demo
      messages: [
        {
          role: "user",
          content: "Write a short poem about coding",
        },
      ],
    });

    let fullContent = "";
    let chunkCount = 0;

    console.log("ğŸ”„ Streaming response:");
    process.stdout.write("ğŸ“ ");

    // Handle streaming events
    stream.on("text", (text) => {
      process.stdout.write(text);
      fullContent += text;
      chunkCount++;
    });

    stream.on("error", (error) => {
      console.error("\nâŒ Stream error:", error);
      throw error;
    });

    // Wait for the final message
    const finalMessage = await stream.finalMessage();

    console.log(); // New line after content
    console.log();
    console.log("âœ… Streaming completed!");
    console.log("ğŸ Stop reason:", finalMessage.stop_reason);

    // Adaptive adds provider information
    const adaptiveFinalMessage = finalMessage as AdaptiveAnthropicResponse;
    if (adaptiveFinalMessage.provider) {
      console.log("ğŸ¢ Provider used:", adaptiveFinalMessage.provider);
    }
    // Model information is part of Anthropic's standard response
    console.log("ğŸ¤– Model used:", adaptiveFinalMessage.model);

    console.log("ğŸ“Š Streaming statistics:");
    console.log(`   â€¢ Text chunks received: ${chunkCount}`);
    console.log(`   â€¢ Total content length: ${fullContent.length} characters`);

    // Usage information
    if (finalMessage.usage) {
      console.log("ğŸ“Š Final usage:");
      console.log(`   â€¢ Input tokens: ${finalMessage.usage.input_tokens}`);
      console.log(`   â€¢ Output tokens: ${finalMessage.usage.output_tokens}`);
    }

    console.log();
    console.log("âœ¨ Streaming example completed successfully!");
  } catch (error) {
    console.error("âŒ Streaming Error:", error);

    if (error instanceof Anthropic.APIError) {
      console.error("ğŸ”§ API Error Details:");
      console.error("   â€¢ Status:", error.status);
      console.error("   â€¢ Message:", error.message);
      if (error.error) {
        console.error("   â€¢ Error type:", error.error.type);
      }
    }

    throw error;
  }
}

async function main() {
  console.log("ğŸš€ Starting Anthropic SDK example with Adaptive...");
  console.log("ğŸ“¡ Using endpoint:", client.baseURL);
  console.log("ğŸ›ï¸ Using Claude's Messages API format");
  console.log();

  try {
    // Run non-streaming example first
    await nonStreamingExample();

    console.log();
    console.log("=".repeat(50));
    console.log();

    // Run streaming example second
    await streamingExample();

    console.log();
    console.log("=".repeat(50));
    console.log();
    console.log("ğŸ‰ All Anthropic examples completed successfully!");
    console.log(
      "ğŸ’° You're getting cost optimization while keeping Claude's API format.",
    );
    console.log(
      "ğŸ”„ Both streaming and non-streaming work with Anthropic SDK patterns.",
    );
    console.log(
      "ğŸ§  Adaptive intelligently routes to the best available model.",
    );
  } catch (error) {
    console.error("âŒ Example failed:", error);
    process.exit(1);
  }
}

// Run the example
main();
