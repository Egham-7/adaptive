{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ CodeBERT Clustering Optimization\n",
    "\n",
    "**Goal:** Reach 0.4+ silhouette score using CodeBERT embeddings\n",
    "\n",
    "**Previous Results:**\n",
    "- CodeBERT K=5: **0.2517** (7x better than baseline!)\n",
    "- CodeBERT K=10: 0.1569\n",
    "- Best alternative (BGE K=15): 0.1149\n",
    "\n",
    "**Why CodeBERT works:** Natural split between Code MMLU (coding questions) and MMLU (academic questions)\n",
    "\n",
    "**Experiments:**\n",
    "1. Test lower K values (K=2,3,4) - might match natural data structure\n",
    "2. Different clustering algorithms (HDBSCAN, GMM, Spectral)\n",
    "3. Hierarchical clustering (2-level approach)\n",
    "4. Detailed visualization of clusters\n",
    "\n",
    "---\n",
    "**ðŸ“ Designed for Google Colab** - GPU recommended for faster processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ðŸ”§ Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sentence-transformers datasets umap-learn scikit-learn matplotlib seaborn pandas numpy hdbscan\n",
    "\n",
    "print(\"âœ… All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"ðŸŽ® GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"ðŸ’» Running on CPU\")\n",
    "    print(\"   ðŸ’¡ To enable GPU: Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ðŸ“¦ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# Clustering algorithms\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import hdbscan\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Data loading\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ðŸ“¥ Load Data (Same as Before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(max_samples=3500):\n",
    "    \"\"\"\n",
    "    Load MMLU + Code MMLU data:\n",
    "    - 16 MMLU subjects (academic questions)\n",
    "    - 9 Code MMLU subsets (coding questions)\n",
    "    \"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    # MMLU subjects (academic)\n",
    "    mmlu_subsets = [\n",
    "        \"college_computer_science\",\n",
    "        \"high_school_computer_science\",\n",
    "        \"college_mathematics\",\n",
    "        \"high_school_mathematics\",\n",
    "        \"formal_logic\",\n",
    "        \"machine_learning\",\n",
    "        \"college_physics\",\n",
    "        \"high_school_physics\",\n",
    "        \"computer_security\",\n",
    "        \"electrical_engineering\",\n",
    "        \"abstract_algebra\",\n",
    "        \"astronomy\",\n",
    "        \"elementary_mathematics\",\n",
    "        \"college_chemistry\",\n",
    "        \"high_school_chemistry\",\n",
    "        \"conceptual_physics\",\n",
    "    ]\n",
    "    \n",
    "    # Code MMLU subsets (coding)\n",
    "    code_mmlu_subsets = [\n",
    "        \"api_frameworks\",\n",
    "        \"code_completion\",\n",
    "        \"code_repair\",\n",
    "        \"dbms_sql\",\n",
    "        \"execution_prediction\",\n",
    "        \"fill_in_the_middle\",\n",
    "        \"others\",\n",
    "        \"programming_syntax\",\n",
    "        \"software_principles\",\n",
    "    ]\n",
    "    \n",
    "    total_sources = len(mmlu_subsets) + len(code_mmlu_subsets)\n",
    "    questions_per_source = max_samples // total_sources\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"LOADING DATA (MMLU + Code MMLU)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Target: ~{max_samples} questions total\")\n",
    "    print(f\"Questions per source: ~{questions_per_source}\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Load MMLU subjects\n",
    "    print(f\"1. Loading {len(mmlu_subsets)} MMLU subjects...\")\n",
    "    for subset in mmlu_subsets:\n",
    "        try:\n",
    "            dataset = load_dataset(\"cais/mmlu\", subset, split=\"test\", trust_remote_code=True)\n",
    "            count = 0\n",
    "            \n",
    "            for idx, item in enumerate(dataset):\n",
    "                if count >= questions_per_source:\n",
    "                    break\n",
    "                    \n",
    "                question_text = item.get(\"question\", \"\")\n",
    "                choices = item.get(\"choices\", [])\n",
    "                \n",
    "                if question_text and len(choices) == 4:\n",
    "                    questions.append({\n",
    "                        \"question_id\": f\"mmlu_{subset}_{idx}\",\n",
    "                        \"question\": question_text,\n",
    "                        \"category\": f\"mmlu_{subset}\",\n",
    "                        \"data_type\": \"academic\",\n",
    "                    })\n",
    "                    count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   âœ— {subset}: {e}\")\n",
    "    \n",
    "    print(f\"   âœ“ Loaded {sum(1 for q in questions if q['data_type'] == 'academic')} academic questions\")\n",
    "    \n",
    "    # 2. Load Code MMLU subsets\n",
    "    print(f\"\\n2. Loading {len(code_mmlu_subsets)} Code MMLU subsets...\")\n",
    "    for subset in code_mmlu_subsets:\n",
    "        try:\n",
    "            dataset = load_dataset(\"Fsoft-AIC/CodeMMLU\", subset, split=\"test\", trust_remote_code=True)\n",
    "            count = 0\n",
    "            \n",
    "            for idx, item in enumerate(dataset):\n",
    "                if count >= questions_per_source:\n",
    "                    break\n",
    "                    \n",
    "                question_text = item.get(\"question\", \"\")\n",
    "                \n",
    "                if question_text:\n",
    "                    questions.append({\n",
    "                        \"question_id\": f\"code_mmlu_{subset}_{idx}\",\n",
    "                        \"question\": question_text,\n",
    "                        \"category\": f\"code_mmlu_{subset}\",\n",
    "                        \"data_type\": \"code\",\n",
    "                    })\n",
    "                    count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   âœ— {subset}: {e}\")\n",
    "    \n",
    "    print(f\"   âœ“ Loaded {sum(1 for q in questions if q['data_type'] == 'code')} code questions\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ… Total: {len(questions)} questions\")\n",
    "    print(f\"   Academic: {sum(1 for q in questions if q['data_type'] == 'academic')}\")\n",
    "    print(f\"   Code: {sum(1 for q in questions if q['data_type'] == 'code')}\")\n",
    "    print(f\"   Categories: {len(set(q['category'] for q in questions))}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return questions\n",
    "\n",
    "# Load data\n",
    "questions = load_training_data(max_samples=3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ðŸ§  Extract CodeBERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING CODEBERT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load CodeBERT model\n",
    "model = SentenceTransformer(\"microsoft/codebert-base\", device=device)\n",
    "print(f\"âœ… Model loaded on {device}\")\n",
    "\n",
    "# Extract texts\n",
    "texts = [q[\"question\"] for q in questions]\n",
    "data_types = [q[\"data_type\"] for q in questions]\n",
    "categories = [q[\"category\"] for q in questions]\n",
    "\n",
    "print(f\"\\nEncoding {len(texts)} questions...\")\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=False,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"   Mean: {embeddings.mean():.4f}, Std: {embeddings.std():.4f}\")\n",
    "\n",
    "# Normalize\n",
    "embeddings_norm = normalize(embeddings, norm='l2')\n",
    "print(f\"âœ… Normalized embeddings ready\")\n",
    "\n",
    "# Free GPU memory\n",
    "del model\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ðŸŽ¨ Visualize Embeddings (Code vs Academic Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary labels for visualization\n",
    "binary_labels = [0 if dt == \"academic\" else 1 for dt in data_types]\n",
    "\n",
    "print(\"Running UMAP for visualization...\")\n",
    "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1, metric='cosine')\n",
    "embeddings_2d = reducer.fit_transform(embeddings_norm)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Binary (Code vs Academic)\n",
    "colors_binary = ['#FF6B6B' if label == 0 else '#4ECDC4' for label in binary_labels]\n",
    "ax1.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors_binary, alpha=0.6, s=20, edgecolors='black', linewidth=0.3)\n",
    "ax1.set_title('CodeBERT: Code vs Academic Split', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('UMAP 1')\n",
    "ax1.set_ylabel('UMAP 2')\n",
    "ax1.legend(handles=[\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF6B6B', markersize=10, label='Academic (MMLU)'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#4ECDC4', markersize=10, label='Code (Code MMLU)')\n",
    "])\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: All 25 categories\n",
    "unique_categories = sorted(set(categories))\n",
    "category_colors = {cat: i for i, cat in enumerate(unique_categories)}\n",
    "colors_cat = [category_colors[cat] for cat in categories]\n",
    "scatter = ax2.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors_cat, cmap='tab20', alpha=0.6, s=20, edgecolors='black', linewidth=0.3)\n",
    "ax2.set_title('CodeBERT: All 25 Categories', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('UMAP 1')\n",
    "ax2.set_ylabel('UMAP 2')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualization complete\")\n",
    "print(f\"\\nðŸ’¡ Observation: Clear separation between Code (cyan) and Academic (red) clusters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ðŸ”¬ Experiment 1: Lower K Values (K=2,3,4)\n",
    "\n",
    "Hypothesis: K=2 or K=3 might match natural data structure better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lower K values\n",
    "k_values = [2, 3, 4, 5, 6, 8, 10, 15, 20, 25, 30]\n",
    "results = []\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING K-MEANS WITH DIFFERENT K\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"K={k:2d}: \", end='')\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
    "    labels = kmeans.fit_predict(embeddings_norm)\n",
    "    \n",
    "    # Multiple metrics\n",
    "    silhouette = silhouette_score(embeddings_norm, labels, metric='cosine')\n",
    "    calinski = calinski_harabasz_score(embeddings_norm, labels)\n",
    "    davies = davies_bouldin_score(embeddings_norm, labels)\n",
    "    \n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'silhouette': silhouette,\n",
    "        'calinski_harabasz': calinski,\n",
    "        'davies_bouldin': davies,\n",
    "        'inertia': kmeans.inertia_\n",
    "    })\n",
    "    \n",
    "    status = \"âœ… TARGET!\" if silhouette >= 0.4 else \"\"\n",
    "    print(f\"Silhouette={silhouette:.4f} {status}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nâœ… Testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Silhouette\n",
    "axes[0,0].plot(results_df['k'], results_df['silhouette'], marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0,0].axhline(y=0.4, color='green', linestyle='--', linewidth=2, label='ðŸŽ¯ Target: 0.4')\n",
    "axes[0,0].axhline(y=0.0353, color='red', linestyle='--', linewidth=2, alpha=0.5, label='ðŸ“Š Baseline: 0.0353')\n",
    "axes[0,0].set_xlabel('K')\n",
    "axes[0,0].set_ylabel('Silhouette Score')\n",
    "axes[0,0].set_title('Silhouette Score vs K', fontweight='bold')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz (higher is better)\n",
    "axes[0,1].plot(results_df['k'], results_df['calinski_harabasz'], marker='s', linewidth=2, markersize=8, color='coral')\n",
    "axes[0,1].set_xlabel('K')\n",
    "axes[0,1].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[0,1].set_title('Calinski-Harabasz Index vs K (â†‘ better)', fontweight='bold')\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin (lower is better)\n",
    "axes[1,0].plot(results_df['k'], results_df['davies_bouldin'], marker='^', linewidth=2, markersize=8, color='purple')\n",
    "axes[1,0].set_xlabel('K')\n",
    "axes[1,0].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1,0].set_title('Davies-Bouldin Index vs K (â†“ better)', fontweight='bold')\n",
    "axes[1,0].grid(alpha=0.3)\n",
    "\n",
    "# Inertia\n",
    "axes[1,1].plot(results_df['k'], results_df['inertia'], marker='D', linewidth=2, markersize=8, color='teal')\n",
    "axes[1,1].set_xlabel('K')\n",
    "axes[1,1].set_ylabel('Inertia')\n",
    "axes[1,1].set_title('Inertia vs K (Elbow Method)', fontweight='bold')\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best\n",
    "best = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST K-MEANS CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"K: {int(best['k'])}\")\n",
    "print(f\"Silhouette: {best['silhouette']:.6f}\")\n",
    "print(f\"Calinski-Harabasz: {best['calinski_harabasz']:.2f}\")\n",
    "print(f\"Davies-Bouldin: {best['davies_bouldin']:.4f}\")\n",
    "\n",
    "if best['silhouette'] >= 0.4:\n",
    "    print(\"\\nðŸŽ‰ âœ… TARGET ACHIEVED!\")\n",
    "else:\n",
    "    gap = 0.4 - best['silhouette']\n",
    "    print(f\"\\nâš ï¸  Gap to target: {gap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ðŸ”¬ Experiment 2: Different Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best K from previous experiment\n",
    "best_k = int(results_df.loc[results_df['silhouette'].idxmax(), 'k'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"TESTING DIFFERENT ALGORITHMS (K={best_k})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "algorithm_results = []\n",
    "\n",
    "# 1. K-Means (baseline)\n",
    "print(\"\\n1. K-Means: \", end='')\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "labels_kmeans = kmeans.fit_predict(embeddings_norm)\n",
    "sil_kmeans = silhouette_score(embeddings_norm, labels_kmeans, metric='cosine')\n",
    "print(f\"Silhouette = {sil_kmeans:.4f}\")\n",
    "algorithm_results.append({'algorithm': 'K-Means', 'silhouette': sil_kmeans, 'labels': labels_kmeans})\n",
    "\n",
    "# 2. Gaussian Mixture Model\n",
    "print(\"2. Gaussian Mixture: \", end='')\n",
    "gmm = GaussianMixture(n_components=best_k, random_state=42, covariance_type='full')\n",
    "labels_gmm = gmm.fit_predict(embeddings_norm)\n",
    "sil_gmm = silhouette_score(embeddings_norm, labels_gmm, metric='cosine')\n",
    "print(f\"Silhouette = {sil_gmm:.4f}\")\n",
    "algorithm_results.append({'algorithm': 'Gaussian Mixture', 'silhouette': sil_gmm, 'labels': labels_gmm})\n",
    "\n",
    "# 3. Spectral Clustering\n",
    "print(\"3. Spectral Clustering: \", end='')\n",
    "spectral = SpectralClustering(n_clusters=best_k, random_state=42, affinity='cosine')\n",
    "labels_spectral = spectral.fit_predict(embeddings_norm)\n",
    "sil_spectral = silhouette_score(embeddings_norm, labels_spectral, metric='cosine')\n",
    "print(f\"Silhouette = {sil_spectral:.4f}\")\n",
    "algorithm_results.append({'algorithm': 'Spectral', 'silhouette': sil_spectral, 'labels': labels_spectral})\n",
    "\n",
    "# 4. Agglomerative (Hierarchical)\n",
    "print(\"4. Agglomerative (Ward): \", end='')\n",
    "agg = AgglomerativeClustering(n_clusters=best_k, linkage='ward')\n",
    "labels_agg = agg.fit_predict(embeddings_norm)\n",
    "sil_agg = silhouette_score(embeddings_norm, labels_agg, metric='cosine')\n",
    "print(f\"Silhouette = {sil_agg:.4f}\")\n",
    "algorithm_results.append({'algorithm': 'Agglomerative', 'silhouette': sil_agg, 'labels': labels_agg})\n",
    "\n",
    "# 5. HDBSCAN (density-based, finds K automatically)\n",
    "print(\"5. HDBSCAN (auto K): \", end='')\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=50, metric='cosine', min_samples=10)\n",
    "labels_hdbscan = clusterer.fit_predict(embeddings_norm)\n",
    "\n",
    "# Filter out noise points (-1 labels)\n",
    "mask = labels_hdbscan >= 0\n",
    "if mask.sum() > 0 and len(set(labels_hdbscan[mask])) > 1:\n",
    "    sil_hdbscan = silhouette_score(embeddings_norm[mask], labels_hdbscan[mask], metric='cosine')\n",
    "    n_clusters = len(set(labels_hdbscan[mask]))\n",
    "    n_noise = (labels_hdbscan == -1).sum()\n",
    "    print(f\"Silhouette = {sil_hdbscan:.4f} (K={n_clusters}, noise={n_noise})\")\n",
    "    algorithm_results.append({'algorithm': f'HDBSCAN (K={n_clusters})', 'silhouette': sil_hdbscan, 'labels': labels_hdbscan})\n",
    "else:\n",
    "    print(\"Failed (all noise or single cluster)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot algorithm comparison\n",
    "alg_df = pd.DataFrame(algorithm_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(alg_df['algorithm'], alg_df['silhouette'], color='skyblue', edgecolor='black')\n",
    "ax.axvline(x=0.4, color='green', linestyle='--', linewidth=2, label='ðŸŽ¯ Target: 0.4')\n",
    "ax.set_xlabel('Silhouette Score', fontsize=12)\n",
    "ax.set_title('Algorithm Comparison (CodeBERT Embeddings)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Annotate bars\n",
    "for i, (bar, val) in enumerate(zip(bars, alg_df['silhouette'])):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "            va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best\n",
    "best_alg = alg_df.loc[alg_df['silhouette'].idxmax()]\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST ALGORITHM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Algorithm: {best_alg['algorithm']}\")\n",
    "print(f\"Silhouette: {best_alg['silhouette']:.6f}\")\n",
    "\n",
    "if best_alg['silhouette'] >= 0.4:\n",
    "    print(\"\\nðŸŽ‰ âœ… TARGET ACHIEVED!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Gap to target: {0.4 - best_alg['silhouette']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ðŸ”¬ Experiment 3: Hierarchical 2-Level Clustering\n",
    "\n",
    "**Strategy:**\n",
    "1. Level 1: Split into Code vs Academic (K=2)\n",
    "2. Level 2: Sub-cluster each group separately\n",
    "   - Code cluster â†’ K=5 or best K for code questions\n",
    "   - Academic cluster â†’ K=10 or best K for academic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"HIERARCHICAL 2-LEVEL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Level 1: Binary split (Code vs Academic)\n",
    "print(\"\\nLevel 1: Splitting Code vs Academic...\")\n",
    "kmeans_l1 = KMeans(n_clusters=2, random_state=42, n_init=20)\n",
    "labels_l1 = kmeans_l1.fit_predict(embeddings_norm)\n",
    "sil_l1 = silhouette_score(embeddings_norm, labels_l1, metric='cosine')\n",
    "print(f\"  Silhouette (Level 1): {sil_l1:.4f}\")\n",
    "\n",
    "# Identify which cluster is code vs academic\n",
    "cluster_0_code_pct = sum([1 for i, dt in enumerate(data_types) if labels_l1[i] == 0 and dt == 'code']) / sum(labels_l1 == 0)\n",
    "cluster_1_code_pct = sum([1 for i, dt in enumerate(data_types) if labels_l1[i] == 1 and dt == 'code']) / sum(labels_l1 == 1)\n",
    "\n",
    "code_cluster_id = 0 if cluster_0_code_pct > cluster_1_code_pct else 1\n",
    "academic_cluster_id = 1 - code_cluster_id\n",
    "\n",
    "print(f\"  Cluster {code_cluster_id}: {cluster_0_code_pct*100 if code_cluster_id==0 else cluster_1_code_pct*100:.1f}% code (CODE cluster)\")\n",
    "print(f\"  Cluster {academic_cluster_id}: {(1-cluster_1_code_pct)*100 if academic_cluster_id==1 else (1-cluster_0_code_pct)*100:.1f}% academic (ACADEMIC cluster)\")\n",
    "\n",
    "# Get indices for each cluster\n",
    "code_indices = np.where(labels_l1 == code_cluster_id)[0]\n",
    "academic_indices = np.where(labels_l1 == academic_cluster_id)[0]\n",
    "\n",
    "print(f\"\\n  Code cluster size: {len(code_indices)}\")\n",
    "print(f\"  Academic cluster size: {len(academic_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 2: Sub-cluster each group\n",
    "print(\"\\nLevel 2: Sub-clustering each group...\")\n",
    "\n",
    "# Find optimal K for code cluster\n",
    "print(\"\\n  Testing K for CODE cluster...\")\n",
    "code_embeddings = embeddings_norm[code_indices]\n",
    "best_k_code = 5\n",
    "best_sil_code = 0\n",
    "\n",
    "for k in [3, 4, 5, 6, 8]:\n",
    "    kmeans_code = KMeans(n_clusters=k, random_state=42)\n",
    "    labels_code = kmeans_code.fit_predict(code_embeddings)\n",
    "    sil_code = silhouette_score(code_embeddings, labels_code, metric='cosine')\n",
    "    print(f\"    K={k}: Silhouette={sil_code:.4f}\")\n",
    "    if sil_code > best_sil_code:\n",
    "        best_sil_code = sil_code\n",
    "        best_k_code = k\n",
    "\n",
    "print(f\"  â†’ Best K for code: {best_k_code} (silhouette={best_sil_code:.4f})\")\n",
    "\n",
    "# Find optimal K for academic cluster\n",
    "print(\"\\n  Testing K for ACADEMIC cluster...\")\n",
    "academic_embeddings = embeddings_norm[academic_indices]\n",
    "best_k_academic = 10\n",
    "best_sil_academic = 0\n",
    "\n",
    "for k in [5, 8, 10, 12, 15]:\n",
    "    kmeans_academic = KMeans(n_clusters=k, random_state=42)\n",
    "    labels_academic = kmeans_academic.fit_predict(academic_embeddings)\n",
    "    sil_academic = silhouette_score(academic_embeddings, labels_academic, metric='cosine')\n",
    "    print(f\"    K={k}: Silhouette={sil_academic:.4f}\")\n",
    "    if sil_academic > best_sil_academic:\n",
    "        best_sil_academic = sil_academic\n",
    "        best_k_academic = k\n",
    "\n",
    "print(f\"  â†’ Best K for academic: {best_k_academic} (silhouette={best_sil_academic:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final hierarchical clustering with best K values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cluster code\n",
    "kmeans_code_final = KMeans(n_clusters=best_k_code, random_state=42)\n",
    "labels_code_final = kmeans_code_final.fit_predict(code_embeddings)\n",
    "\n",
    "# Cluster academic\n",
    "kmeans_academic_final = KMeans(n_clusters=best_k_academic, random_state=42)\n",
    "labels_academic_final = kmeans_academic_final.fit_predict(academic_embeddings)\n",
    "\n",
    "# Combine labels (offset academic labels to avoid overlap)\n",
    "hierarchical_labels = np.zeros(len(embeddings_norm), dtype=int)\n",
    "hierarchical_labels[code_indices] = labels_code_final\n",
    "hierarchical_labels[academic_indices] = labels_academic_final + best_k_code  # Offset\n",
    "\n",
    "# Calculate overall silhouette\n",
    "sil_hierarchical = silhouette_score(embeddings_norm, hierarchical_labels, metric='cosine')\n",
    "\n",
    "print(f\"\\nLevel 1: K=2 (Code vs Academic)\")\n",
    "print(f\"  Silhouette: {sil_l1:.4f}\")\n",
    "print(f\"\\nLevel 2:\")\n",
    "print(f\"  Code cluster: K={best_k_code}, Silhouette={best_sil_code:.4f}\")\n",
    "print(f\"  Academic cluster: K={best_k_academic}, Silhouette={best_sil_academic:.4f}\")\n",
    "print(f\"\\nTotal clusters: {best_k_code + best_k_academic}\")\n",
    "print(f\"Overall Silhouette: {sil_hierarchical:.6f}\")\n",
    "\n",
    "if sil_hierarchical >= 0.4:\n",
    "    print(\"\\nðŸŽ‰ âœ… TARGET ACHIEVED WITH HIERARCHICAL CLUSTERING!\")\n",
    "else:\n",
    "    gap = 0.4 - sil_hierarchical\n",
    "    print(f\"\\nâš ï¸  Gap to target: {gap:.4f}\")\n",
    "    print(\"\\nðŸ’¡ Weighted silhouette (by cluster size) might be higher!\")\n",
    "    weighted_sil = (len(code_indices) * best_sil_code + len(academic_indices) * best_sil_academic) / len(embeddings_norm)\n",
    "    print(f\"   Weighted average: {weighted_sil:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ðŸ“Š Final Summary & Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY: CODEBERT CLUSTERING EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š EXPERIMENT RESULTS:\")\n",
    "print(f\"\\n1. K-Means with different K:\")\n",
    "best_kmeans = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "print(f\"   Best: K={int(best_kmeans['k'])}, Silhouette={best_kmeans['silhouette']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. Different algorithms (K={best_k}):\")\n",
    "for _, row in alg_df.iterrows():\n",
    "    print(f\"   {row['algorithm']}: {row['silhouette']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Hierarchical 2-level:\")\n",
    "print(f\"   Overall: {sil_hierarchical:.4f}\")\n",
    "print(f\"   Level 1 (K=2): {sil_l1:.4f}\")\n",
    "print(f\"   Level 2 Code (K={best_k_code}): {best_sil_code:.4f}\")\n",
    "print(f\"   Level 2 Academic (K={best_k_academic}): {best_sil_academic:.4f}\")\n",
    "\n",
    "# Find absolute best\n",
    "all_results = [\n",
    "    ('K-Means', best_kmeans['silhouette']),\n",
    "    ('Hierarchical', sil_hierarchical),\n",
    "] + [(row['algorithm'], row['silhouette']) for _, row in alg_df.iterrows()]\n",
    "\n",
    "best_overall = max(all_results, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ† BEST OVERALL CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Method: {best_overall[0]}\")\n",
    "print(f\"Silhouette: {best_overall[1]:.6f}\")\n",
    "print(f\"Improvement over baseline (0.0353): {(best_overall[1] - 0.0353) / 0.0353 * 100:+.1f}%\")\n",
    "\n",
    "if best_overall[1] >= 0.4:\n",
    "    print(\"\\nðŸŽ‰ ðŸŽ‰ ðŸŽ‰ TARGET ACHIEVED! ðŸŽ‰ ðŸŽ‰ ðŸŽ‰\")\n",
    "else:\n",
    "    gap = 0.4 - best_overall[1]\n",
    "    print(f\"\\nâš ï¸  Gap to target 0.4: {gap:.4f}\")\n",
    "    print(\"\\nðŸ’¡ NEXT STEPS TO REACH 0.4+:\")\n",
    "    print(\"   1. Try more training data (currently ~3500 questions)\")\n",
    "    print(\"   2. Test other code-specific models (GraphCodeBERT, CodeT5, StarEncoder)\")\n",
    "    print(\"   3. Feature engineering: Combine CodeBERT + statistical features\")\n",
    "    print(\"   4. Data cleaning: Remove outliers/noise\")\n",
    "    print(\"   5. Try softer clustering (Fuzzy C-Means, Soft K-Means)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ðŸ’¾ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('codebert_kmeans_results.csv', index=False)\n",
    "alg_df[['algorithm', 'silhouette']].to_csv('codebert_algorithm_comparison.csv', index=False)\n",
    "\n",
    "import json\n",
    "final_config = {\n",
    "    'best_method': best_overall[0],\n",
    "    'best_silhouette': float(best_overall[1]),\n",
    "    'target_achieved': bool(best_overall[1] >= 0.4),\n",
    "    'improvement_pct': float((best_overall[1] - 0.0353) / 0.0353 * 100),\n",
    "    'baseline': 0.0353,\n",
    "    'experiments': {\n",
    "        'kmeans_best_k': int(best_kmeans['k']),\n",
    "        'kmeans_best_silhouette': float(best_kmeans['silhouette']),\n",
    "        'hierarchical_overall': float(sil_hierarchical),\n",
    "        'hierarchical_level1': float(sil_l1),\n",
    "        'hierarchical_code_k': int(best_k_code),\n",
    "        'hierarchical_academic_k': int(best_k_academic)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('codebert_best_config.json', 'w') as f:\n",
    "    json.dump(final_config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Results saved:\")\n",
    "print(\"  - codebert_kmeans_results.csv\")\n",
    "print(\"  - codebert_algorithm_comparison.csv\")\n",
    "print(\"  - codebert_best_config.json\")\n",
    "print(\"\\nðŸ“¥ Download these files from Colab sidebar!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
