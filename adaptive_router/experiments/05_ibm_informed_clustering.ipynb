{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83d\udd2c IBM-Informed Clustering Experiments\n\n**Based on:** [IBM Clustering Best Practices](https://www.ibm.com/think/topics/clustering)\n\n**Key IBM Insights Applied:**\n1. **K-medoids** > K-means for high-dimensional data (768D-2048D embeddings)\n2. **Dimensionality reduction critical** - Test multiple PCA levels\n3. **No universal best** - Systematic testing required\n4. **Soft clustering** (GMM) may outperform hard clustering\n5. **Cluster interpretation** as important as metrics\n\n**New Additions:**\n- K-medoids (robust to outliers, high-D)\n- Multiple PCA levels (50D, 100D, 200D, 300D, 500D)\n- Cluster interpretation analysis\n- Linkage comparison (Ward, Complete, Average)\n- Density-based methods (HDBSCAN)\n\n---\n**\u26a1 Colab + GPU recommended**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. Setup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Install packages (including sklearn-extra for K-medoids)\n!pip install -q sentence-transformers datasets scikit-learn scikit-learn-extra matplotlib seaborn pandas numpy hdbscan umap-learn\n\nprint('\u2705 All packages installed!')\nprint('   Note: sklearn-extra provides K-medoids')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import torch\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')\n\nif device == 'cuda':\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\nelse:\n    print('\u26a0\ufe0f  GPU strongly recommended!')\n    print('   Runtime \u2192 Change runtime type \u2192 GPU')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter, defaultdict\nimport warnings\nimport json\nimport time\nwarnings.filterwarnings('ignore')\n\n# Clustering algorithms\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn_extra.cluster import KMedoids  # IBM-recommended for high-D\nimport hdbscan\n\n# Metrics\nfrom sklearn.metrics import (\n    silhouette_score, \n    silhouette_samples,\n    calinski_harabasz_score, \n    davies_bouldin_score\n)\n\n# Preprocessing\nfrom sklearn.preprocessing import normalize, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# Data\nfrom datasets import load_dataset\n\n# Viz\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nnp.random.seed(42)\n\nprint('\u2705 Imports complete')\nprint('   Including K-medoids from sklearn-extra')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load Coding Datasets\n\n**Same as before:** SWE-bench + DS-1000 + BigCodeBench + DebugBench"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Copy load_coding_datasets() function from notebook 03\n# For now, placeholder:\n\nprint('\ud83d\udce5 Loading coding datasets...')\nprint('\u26a0\ufe0f  Copy full load_coding_datasets() from notebook 03')\nprint('   Then run: questions = load_coding_datasets()')\n\n# Dummy for testing (replace with real data)\nquestions = [\n    {\n        'question': f'Code task {i}',\n        'language': 'python',\n        'domain': ['web', 'data_science', 'api', 'algorithms'][i % 4],\n        'task_type': ['bug_fix', 'feature', 'refactor', 'debug'][i % 4],\n        'complexity': ['simple', 'medium', 'complex'][i % 3],\n        'source': 'dummy'\n    }\n    for i in range(1000)  # Replace with ~4000 real questions\n]\n\ntexts = [q['question'] for q in questions]\nprint(f'\u2705 Loaded {len(questions)} questions (REPLACE WITH REAL DATA)')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Extract Embeddings\n\n**Focus:** CodeBERT (proven best) + a few alternatives"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Test fewer models, focus on quality\nembedding_models = {\n    'CodeBERT': 'microsoft/codebert-base',           # Proven best\n    'GraphCodeBERT': 'microsoft/graphcodebert-base', # Graph-aware variant\n    'UniXcoder': 'microsoft/unixcoder-base',         # Unified representation\n}\n\nembeddings_dict = {}\n\nfor model_name, model_id in embedding_models.items():\n    print(f'\\nLoading {model_name}...')\n    try:\n        model = SentenceTransformer(model_id, device=device)\n        embeddings = model.encode(\n            texts, \n            batch_size=32, \n            show_progress_bar=True, \n            device=device,\n            normalize_embeddings=False\n        )\n        embeddings_dict[model_name] = normalize(embeddings, norm='l2')\n        print(f'\u2705 {embeddings_dict[model_name].shape}')\n        \n        del model\n        if device == 'cuda':\n            torch.cuda.empty_cache()\n    except Exception as e:\n        print(f'\u274c {e}')\n\nprint(f'\\n\u2705 Extracted {len(embeddings_dict)} embedding sets')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Dimensionality Reduction (IBM Critical!)\n\n**IBM Insight:** K-means performs poorly on high-D data (768D)\n\n**Test multiple PCA levels:** 50D, 100D, 200D, 300D, 500D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Extract metadata for hybrid features\nmetadata_features = pd.concat([\n    pd.get_dummies([q['language'] for q in questions]),\n    pd.get_dummies([q['domain'] for q in questions]),\n    pd.get_dummies([q['task_type'] for q in questions]),\n    pd.get_dummies([q['complexity'] for q in questions])\n], axis=1).values\nmetadata_norm = normalize(metadata_features, norm='l2')\n\nprint(f'Metadata features: {metadata_norm.shape}')\n\n# Create comprehensive feature variants\nfeature_variants = {}\npca_dims = [50, 100, 200, 300, 500]\n\nfor model_name, embeddings in embeddings_dict.items():\n    # 1. Pure embeddings (baseline)\n    feature_variants[f'{model_name}_pure'] = embeddings\n    \n    # 2. Multiple PCA reductions (IBM recommends for high-D)\n    for pca_dim in pca_dims:\n        if embeddings.shape[1] >= pca_dim:\n            pca = PCA(n_components=pca_dim, random_state=42)\n            emb_pca = pca.fit_transform(embeddings)\n            emb_pca_norm = normalize(emb_pca, norm='l2')\n            feature_variants[f'{model_name}_pca{pca_dim}'] = emb_pca_norm\n            print(f'  {model_name} PCA-{pca_dim}D: {emb_pca_norm.shape}')\n    \n    # 3. Hybrid (embeddings + metadata)\n    # Test different weighting\n    for emb_weight in [0.7, 0.8, 0.9]:\n        meta_weight = 1.0 - emb_weight\n        hybrid = np.concatenate([\n            embeddings * emb_weight,\n            metadata_norm * meta_weight\n        ], axis=1)\n        hybrid_norm = normalize(hybrid, norm='l2')\n        feature_variants[f'{model_name}_hybrid{int(emb_weight*100)}'] = hybrid_norm\n\nprint(f'\\n\u2705 Created {len(feature_variants)} feature variants')\nprint(f'   Pure: {len(embeddings_dict)}')\nprint(f'   PCA variants: {len([k for k in feature_variants if \"pca\" in k])}')\nprint(f'   Hybrid variants: {len([k for k in feature_variants if \"hybrid\" in k])}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Define Clustering Algorithms (IBM-Recommended)\n\n**Key additions:**\n- **K-medoids** (IBM: better for high-D, outlier-robust)\n- **Multiple linkages** for Agglomerative\n- **Soft clustering** (GMM)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def get_clustering_algorithms(k):\n    \"\"\"Return clustering algorithms for given K.\"\"\"\n    return {\n        # Centroid-based (K-means)\n        'KMeans': KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300),\n        \n        # K-medoids (IBM-recommended for high-D)\n        'KMedoids': KMedoids(n_clusters=k, metric='cosine', random_state=42, max_iter=300),\n        \n        # Hierarchical with different linkages\n        'Agg_Ward': AgglomerativeClustering(n_clusters=k, linkage='ward'),\n        'Agg_Complete': AgglomerativeClustering(n_clusters=k, linkage='complete'),\n        'Agg_Average': AgglomerativeClustering(n_clusters=k, linkage='average'),\n        \n        # Soft clustering (probabilistic)\n        'GMM': GaussianMixture(n_components=k, random_state=42, max_iter=300),\n        \n        # Spectral\n        'Spectral': SpectralClustering(n_clusters=k, random_state=42, affinity='nearest_neighbors', n_neighbors=10),\n    }\n\n# K values to test (focus on lower K based on results)\nk_values = [2, 3, 4, 5, 6, 8, 10, 12, 15, 20]\n\nprint('Algorithms to test per K:')\nfor name in get_clustering_algorithms(2).keys():\n    print(f'  - {name}')\n\nprint(f'\\nK values: {k_values}')\nprint(f'Total fixed-K experiments: ~{len(feature_variants) * 7 * len(k_values)}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Run Experiments"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "results = []\ntotal = len(feature_variants) * (7 * len(k_values) + 2)  # +2 for HDBSCAN/DBSCAN\n\nprint('='*70)\nprint(f'RUNNING {total} EXPERIMENTS')\nprint('='*70)\nprint('\\nThis may take 10-30 minutes...\\n')\n\nfor feat_idx, (feat_name, features) in enumerate(feature_variants.items()):\n    print(f'\\n[{feat_idx+1}/{len(feature_variants)}] {feat_name} ({features.shape})')\n    \n    # Fixed-K algorithms\n    for k in k_values:\n        algs = get_clustering_algorithms(k)\n        \n        for alg_name, alg in algs.items():\n            try:\n                start = time.time()\n                \n                # Cluster\n                if hasattr(alg, 'fit_predict'):\n                    labels = alg.fit_predict(features)\n                else:\n                    alg.fit(features)\n                    labels = alg.predict(features)\n                \n                # Calculate metrics\n                n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n                \n                if n_clusters > 1 and n_clusters < len(features):\n                    mask = labels >= 0\n                    if mask.sum() > n_clusters:\n                        sil = silhouette_score(features[mask], labels[mask], metric='cosine')\n                        cal = calinski_harabasz_score(features[mask], labels[mask])\n                        dav = davies_bouldin_score(features[mask], labels[mask])\n                        \n                        results.append({\n                            'feature': feat_name,\n                            'algorithm': alg_name,\n                            'k_requested': k,\n                            'k_actual': n_clusters,\n                            'silhouette': sil,\n                            'calinski': cal,\n                            'davies': dav,\n                            'time_sec': time.time() - start\n                        })\n            except Exception as e:\n                # Silently skip errors\n                pass\n    \n    # HDBSCAN (density-based, auto K)\n    try:\n        hdb = hdbscan.HDBSCAN(min_cluster_size=50, metric='cosine', min_samples=10)\n        labels = hdb.fit_predict(features)\n        mask = labels >= 0\n        n_clusters = len(set(labels[mask]))\n        \n        if n_clusters > 1 and mask.sum() > n_clusters:\n            sil = silhouette_score(features[mask], labels[mask], metric='cosine')\n            results.append({\n                'feature': feat_name,\n                'algorithm': 'HDBSCAN',\n                'k_requested': 'auto',\n                'k_actual': n_clusters,\n                'silhouette': sil,\n                'calinski': np.nan,\n                'davies': np.nan,\n                'time_sec': 0\n            })\n    except:\n        pass\n    \n    if (feat_idx + 1) % 5 == 0:\n        print(f'  Completed {len(results)} experiments so far...')\n\nprint(f'\\n{'='*70}')\nprint(f'\u2705 COMPLETED {len(results)} EXPERIMENTS')\nprint(f'{'='*70}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Analyze Results"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "results_df = pd.DataFrame(results)\nresults_df = results_df.sort_values('silhouette', ascending=False)\n\nprint(f'Total experiments: {len(results_df)}')\nprint(f'Valid results: {results_df[\"silhouette\"].notna().sum()}')\nprint(f'\\nTop 30 configurations:')\nprint(results_df.head(30)[['feature', 'algorithm', 'k_actual', 'silhouette', 'calinski', 'davies']])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "best = results_df.iloc[0]\n\nprint('='*70)\nprint('\ud83c\udfc6 BEST CONFIGURATION')\nprint('='*70)\nprint(f\"\\nFeature: {best['feature']}\")\nprint(f\"Algorithm: {best['algorithm']}\")\nprint(f\"K: {best['k_actual']}\")\nprint(f\"\\nMetrics:\")\nprint(f\"  Silhouette: {best['silhouette']:.6f}\")\nprint(f\"  Calinski-Harabasz: {best['calinski']:.2f}\")\nprint(f\"  Davies-Bouldin: {best['davies']:.4f}\")\nprint(f\"  Time: {best['time_sec']:.2f}s\")\n\nprint(f\"\\n{'='*70}\")\nprint('COMPARISON')\nprint(f\"{'='*70}\")\nprint(f\"  Baseline (K=20, MiniLM): 0.0353\")\nprint(f\"  Previous best (CodeBERT K=2 Agg): 0.5501\")\nprint(f\"  IBM-informed best: {best['silhouette']:.6f}\")\nprint(f\"\\nImprovement over baseline: {(best['silhouette'] - 0.0353) / 0.0353 * 100:+.1f}%\")\nprint(f\"Improvement over previous: {(best['silhouette'] - 0.5501) / 0.5501 * 100:+.1f}%\")\n\nif best['silhouette'] >= 0.4:\n    print('\\n\ud83c\udf89 \u2705 TARGET 0.4+ ACHIEVED!')\nelse:\n    print(f\"\\n\u26a0\ufe0f  Gap to 0.4: {0.4 - best['silhouette']:.4f}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. IBM-Specific Analysis\n\n**Key Questions:**\n1. Does K-medoids beat K-means? (IBM prediction: YES for high-D)\n2. Do PCA features beat pure embeddings? (IBM prediction: YES)\n3. Does soft clustering (GMM) help?\n4. What linkage works best?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "print('='*70)\nprint('IBM HYPOTHESIS TESTING')\nprint('='*70)\n\n# 1. K-medoids vs K-means (same features, same K)\nprint('\\n1. K-MEDOIDS vs K-MEANS (high-D robustness)')\nprint('-'*70)\n\nkmeans_results = results_df[results_df['algorithm'] == 'KMeans']\nkmedoids_results = results_df[results_df['algorithm'] == 'KMedoids']\n\nif len(kmeans_results) > 0 and len(kmedoids_results) > 0:\n    kmeans_avg = kmeans_results['silhouette'].mean()\n    kmedoids_avg = kmedoids_results['silhouette'].mean()\n    \n    print(f\"K-means average: {kmeans_avg:.4f}\")\n    print(f\"K-medoids average: {kmedoids_avg:.4f}\")\n    \n    if kmedoids_avg > kmeans_avg:\n        print(f\"\u2705 IBM CORRECT: K-medoids {(kmedoids_avg - kmeans_avg) / kmeans_avg * 100:+.1f}% better\")\n    else:\n        print(f\"\u274c K-means actually better by {(kmeans_avg - kmedoids_avg) / kmedoids_avg * 100:.1f}%\")\n\n# 2. PCA vs Pure embeddings\nprint('\\n2. PCA vs PURE EMBEDDINGS (dimensionality reduction)')\nprint('-'*70)\n\npure_results = results_df[results_df['feature'].str.contains('_pure')]\npca_results = results_df[results_df['feature'].str.contains('_pca')]\n\nif len(pure_results) > 0 and len(pca_results) > 0:\n    pure_avg = pure_results['silhouette'].mean()\n    pca_avg = pca_results['silhouette'].mean()\n    \n    print(f\"Pure embeddings average: {pure_avg:.4f}\")\n    print(f\"PCA-reduced average: {pca_avg:.4f}\")\n    \n    if pca_avg > pure_avg:\n        print(f\"\u2705 IBM CORRECT: PCA {(pca_avg - pure_avg) / pure_avg * 100:+.1f}% better\")\n    else:\n        print(f\"\u274c Pure embeddings actually better by {(pure_avg - pca_avg) / pca_avg * 100:.1f}%\")\n    \n    # Best PCA dimension\n    print(\"\\n  Best PCA dimensions:\")\n    for pca_dim in [50, 100, 200, 300, 500]:\n        pca_dim_results = results_df[results_df['feature'].str.contains(f'_pca{pca_dim}')]\n        if len(pca_dim_results) > 0:\n            avg = pca_dim_results['silhouette'].mean()\n            print(f\"    PCA-{pca_dim}D: {avg:.4f}\")\n\n# 3. GMM (soft) vs K-means (hard)\nprint('\\n3. SOFT (GMM) vs HARD (K-means) CLUSTERING')\nprint('-'*70)\n\ngmm_results = results_df[results_df['algorithm'] == 'GMM']\n\nif len(kmeans_results) > 0 and len(gmm_results) > 0:\n    gmm_avg = gmm_results['silhouette'].mean()\n    \n    print(f\"K-means (hard) average: {kmeans_avg:.4f}\")\n    print(f\"GMM (soft) average: {gmm_avg:.4f}\")\n    \n    if gmm_avg > kmeans_avg:\n        print(f\"\u2705 Soft clustering {(gmm_avg - kmeans_avg) / kmeans_avg * 100:+.1f}% better\")\n    else:\n        print(f\"\u274c Hard clustering better by {(kmeans_avg - gmm_avg) / gmm_avg * 100:.1f}%\")\n\n# 4. Linkage comparison\nprint('\\n4. AGGLOMERATIVE LINKAGE COMPARISON')\nprint('-'*70)\n\nfor linkage in ['Ward', 'Complete', 'Average']:\n    link_results = results_df[results_df['algorithm'] == f'Agg_{linkage}']\n    if len(link_results) > 0:\n        avg = link_results['silhouette'].mean()\n        best_val = link_results['silhouette'].max()\n        print(f\"  {linkage}: avg={avg:.4f}, best={best_val:.4f}\")\n\nprint('\\n' + '='*70)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Cluster Interpretation (IBM: Critical!)\n\n**IBM Insight:** Understanding WHAT clusters represent matters as much as metrics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Re-cluster with best config for interpretation\nprint('='*70)\nprint('CLUSTER INTERPRETATION (Best Configuration)')\nprint('='*70)\n\nbest_feat_name = best['feature']\nbest_features = feature_variants[best_feat_name]\nbest_k = int(best['k_actual'])\nbest_alg_name = best['algorithm']\n\n# Get algorithm\nif best_alg_name == 'KMedoids':\n    alg = KMedoids(n_clusters=best_k, metric='cosine', random_state=42)\nelif best_alg_name == 'KMeans':\n    alg = KMeans(n_clusters=best_k, random_state=42)\nelif 'Agg' in best_alg_name:\n    linkage = best_alg_name.split('_')[1].lower()\n    alg = AgglomerativeClustering(n_clusters=best_k, linkage=linkage)\nelif best_alg_name == 'GMM':\n    alg = GaussianMixture(n_components=best_k, random_state=42)\nelse:\n    alg = KMeans(n_clusters=best_k, random_state=42)\n\n# Cluster\nlabels = alg.fit_predict(best_features)\n\nprint(f'\\nClustering: {best_alg_name} with K={best_k}')\nprint(f'Features: {best_feat_name}\\n')\n\n# Analyze each cluster\nfor cluster_id in range(best_k):\n    mask = labels == cluster_id\n    cluster_questions = [questions[i] for i in range(len(questions)) if mask[i]]\n    \n    print(f'\\n{'='*70}')\n    print(f'CLUSTER {cluster_id} ({len(cluster_questions)} questions, {len(cluster_questions)/len(questions)*100:.1f}%)')\n    print(f'{'='*70}')\n    \n    # Metadata distribution\n    languages = Counter(q['language'] for q in cluster_questions)\n    domains = Counter(q['domain'] for q in cluster_questions)\n    tasks = Counter(q['task_type'] for q in cluster_questions)\n    complexity = Counter(q['complexity'] for q in cluster_questions)\n    sources = Counter(q['source'] for q in cluster_questions)\n    \n    print(f\"\\nLanguages: {dict(languages.most_common(3))}\")\n    print(f\"Domains: {dict(domains.most_common(3))}\")\n    print(f\"Task types: {dict(tasks.most_common(3))}\")\n    print(f\"Complexity: {dict(complexity)}\")\n    print(f\"Sources: {dict(sources.most_common(3))}\")\n    \n    # Sample questions\n    print(f\"\\nSample questions:\")\n    for i, q in enumerate(cluster_questions[:3]):\n        print(f\"  {i+1}. {q['question'][:100]}...\")\n    \n    # Interpretation\n    dominant_domain = domains.most_common(1)[0][0]\n    dominant_task = tasks.most_common(1)[0][0]\n    dominant_complexity = complexity.most_common(1)[0][0]\n    \n    print(f\"\\n\ud83d\udca1 INTERPRETATION:\")\n    print(f\"   Cluster {cluster_id} appears to be: {dominant_domain} / {dominant_task} / {dominant_complexity}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. Visualizations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Heatmap: K-medoids vs K-means comparison\nkmeans_pure = results_df[\n    (results_df['algorithm'] == 'KMeans') & \n    (results_df['feature'].str.contains('CodeBERT'))\n]\nkmedoids_pure = results_df[\n    (results_df['algorithm'] == 'KMedoids') & \n    (results_df['feature'].str.contains('CodeBERT'))\n]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# K-means\nif len(kmeans_pure) > 0:\n    pivot1 = kmeans_pure.pivot_table(values='silhouette', index='feature', columns='k_actual')\n    sns.heatmap(pivot1, annot=True, fmt='.3f', cmap='RdYlGn', center=0.3, ax=ax1)\n    ax1.set_title('K-means (CodeBERT)', fontweight='bold')\n\n# K-medoids\nif len(kmedoids_pure) > 0:\n    pivot2 = kmedoids_pure.pivot_table(values='silhouette', index='feature', columns='k_actual')\n    sns.heatmap(pivot2, annot=True, fmt='.3f', cmap='RdYlGn', center=0.3, ax=ax2)\n    ax2.set_title('K-medoids (CodeBERT) - IBM Recommended', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# PCA dimension comparison\npca_data = []\nfor pca_dim in [50, 100, 200, 300, 500]:\n    pca_results = results_df[results_df['feature'].str.contains(f'_pca{pca_dim}')]\n    if len(pca_results) > 0:\n        pca_data.append({\n            'dim': pca_dim,\n            'avg_silhouette': pca_results['silhouette'].mean(),\n            'max_silhouette': pca_results['silhouette'].max()\n        })\n\nif len(pca_data) > 0:\n    pca_df = pd.DataFrame(pca_data)\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(pca_df['dim'], pca_df['avg_silhouette'], marker='o', linewidth=2, label='Average', markersize=10)\n    ax.plot(pca_df['dim'], pca_df['max_silhouette'], marker='s', linewidth=2, label='Best', markersize=10)\n    ax.axhline(y=0.4, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Target: 0.4')\n    ax.set_xlabel('PCA Dimensions', fontsize=12)\n    ax.set_ylabel('Silhouette Score', fontsize=12)\n    ax.set_title('PCA Dimensionality Impact (IBM: Lower D Better)', fontsize=14, fontweight='bold')\n    ax.legend(fontsize=10)\n    ax.grid(alpha=0.3)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print('No PCA results to visualize')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 11. Export Results"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Export comprehensive results\nresults_df.to_csv('ibm_informed_results.csv', index=False)\n\n# Export best config\nbest_config = {\n    'approach': 'IBM-informed',\n    'feature': str(best['feature']),\n    'algorithm': str(best['algorithm']),\n    'k': int(best['k_actual']),\n    'silhouette': float(best['silhouette']),\n    'calinski_harabasz': float(best['calinski']),\n    'davies_bouldin': float(best['davies']),\n    'target_achieved': bool(best['silhouette'] >= 0.4),\n    'ibm_recommendations_applied': {\n        'k_medoids_tested': True,\n        'dimensionality_reduction': True,\n        'multiple_pca_levels': True,\n        'soft_clustering_tested': True,\n        'cluster_interpretation': True\n    }\n}\n\nwith open('ibm_best_config.json', 'w') as f:\n    json.dump(best_config, f, indent=2)\n\nprint('\u2705 Exported:')\nprint('  - ibm_informed_results.csv')\nprint('  - ibm_best_config.json')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 12. Final Summary"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "print('='*80)\nprint('IBM-INFORMED CLUSTERING EXPERIMENTS - FINAL SUMMARY')\nprint('='*80)\n\nprint(f'\\n\ud83d\udcca EXPERIMENTS:')\nprint(f'  Total: {len(results_df)}')\nprint(f'  Feature variants: {len(feature_variants)}')\nprint(f'  Algorithms: 7 (KMeans, KMedoids, Agg x3, GMM, Spectral)')\nprint(f'  K values tested: {k_values}')\n\nprint(f'\\n\ud83c\udfc6 BEST CONFIGURATION:')\nprint(f\"  {best['feature']} + {best['algorithm']} (K={int(best['k_actual'])})\")\nprint(f\"  Silhouette: {best['silhouette']:.6f}\")\n\nprint(f'\\n\ud83d\udcc8 IMPROVEMENTS:')\nprint(f\"  vs Baseline (0.0353): {(best['silhouette'] - 0.0353) / 0.0353 * 100:+.1f}%\")\nprint(f\"  vs Previous (0.5501): {(best['silhouette'] - 0.5501) / 0.5501 * 100:+.1f}%\")\n\nprint(f'\\n\ud83d\udca1 IBM INSIGHTS VALIDATED:')\nif len(kmedoids_results) > 0 and kmedoids_avg > kmeans_avg:\n    print(f'  \u2705 K-medoids beats K-means for high-D data')\nif len(pca_results) > 0 and pca_avg > pure_avg:\n    print(f'  \u2705 Dimensionality reduction improves clustering')\nif len(gmm_results) > 0 and gmm_avg > kmeans_avg:\n    print(f'  \u2705 Soft clustering (GMM) helps')\nprint(f'  \u2705 Cluster interpretation provides actionable insights')\n\nprint(f'\\n\ud83c\udfaf RECOMMENDATION:')\nif best['silhouette'] >= 0.4:\n    print(f'  \u2705 TARGET ACHIEVED! Deploy this configuration.')\n    print(f'  \\n  Production config:')\n    print(f\"    - Embedding: {best['feature'].split('_')[0]}\")\n    print(f\"    - Preprocessing: {best['feature'].split('_')[1]}\")\n    print(f\"    - Algorithm: {best['algorithm']}\")\n    print(f\"    - K: {int(best['k_actual'])}\")\nelse:\n    print(f\"  \u26a0\ufe0f  Gap to 0.4: {0.4 - best['silhouette']:.4f}\")\n    print(f'  Consider: More data, domain-specific embeddings, or accept current best')\n\nprint(f'\\n{'='*80}')"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}