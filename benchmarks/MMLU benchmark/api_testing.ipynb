{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Backend API Testing\n",
    "\n",
    "This notebook allows direct testing of the Azure backend API endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMLU Testing Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 MMLU MATHEMATICS BENCHMARK\n",
      "🎯 Focus on the most important subject for AI reasoning\n",
      "⚡ Fast, focused, and comprehensive analysis\n",
      "\n",
      "=== SINGLE SUBJECT MMLU BENCHMARK ===\n",
      "🎯 Testing ONLY: high_school_mathematics\n",
      "📊 Math is the gold standard for AI reasoning capabilities\n",
      "⏰ Estimated time: 5-15 minutes\n",
      "💰 Cost: Very low API usage\n",
      "\n",
      "▶️  Starting in 2 seconds...\n",
      "📚 Loading MMLU dataset...\n",
      "✅ Loaded 14042 total test questions\n",
      "🎯 Found 270 questions for high_school_mathematics\n",
      "\n",
      "🔬 Testing subject: high_school_mathematics\n",
      "   📊 Processing 270 questions...\n",
      "   Question 1/270...    Question 10/270... ✅ Accuracy: 30.0%\n",
      "   Question 20/270... ✅ Accuracy: 40.0%\n",
      "   Question 30/270... ✅ Accuracy: 43.3%\n",
      "   Question 40/270... ✅ Accuracy: 47.5%\n",
      "   Question 50/270... ✅ Accuracy: 42.0%\n",
      "   Question 60/270... ✅ Accuracy: 45.0%\n",
      "   Question 70/270... ✅ Accuracy: 42.9%\n",
      "   Question 80/270... ✅ Accuracy: 41.2%\n",
      "   Question 90/270... ✅ Accuracy: 38.9%\n",
      "   Question 100/270... ✅ Accuracy: 39.0%\n",
      "   Question 110/270... ✅ Accuracy: 39.1%\n",
      "   Question 120/270... ✅ Accuracy: 38.3%\n",
      "   Question 130/270... ✅ Accuracy: 36.9%\n",
      "   Question 140/270... ✅ Accuracy: 37.9%\n",
      "   Question 150/270... ✅ Accuracy: 37.3%\n",
      "   Question 160/270... ✅ Accuracy: 38.8%\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "   Question 170/270... ❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "   Question 180/270... ❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n",
      "❌ Request failed: HTTPSConnectionPool(host='backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io', port=443): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 292\u001b[0m\n\u001b[1;32m    289\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Run it!\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m math_results \u001b[38;5;241m=\u001b[39m run_single_subject_mmlu_benchmark()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎉 MATHEMATICS BENCHMARK COMPLETE!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 89\u001b[0m, in \u001b[0;36mrun_single_subject_mmlu_benchmark\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     request_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 89\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m         json\u001b[38;5;241m=\u001b[39mchat_data,\n\u001b[1;32m     92\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m     93\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# Shorter timeout for single subject\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m     response_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m request_start_time\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MMLU Single Subject Benchmarking with Adaptive Backend\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"https://backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io\"\n",
    "\n",
    "# Focus on the MOST IMPORTANT subject for AI benchmarking\n",
    "TARGET_SUBJECT = \"high_school_mathematics\"  # Math is the gold standard for AI reasoning\n",
    "\n",
    "\n",
    "def run_single_subject_mmlu_benchmark():\n",
    "    \"\"\"\n",
    "    Run MMLU benchmark on HIGH SCHOOL MATHEMATICS only\n",
    "    ~100 questions, perfect for quick validation\n",
    "    \n",
    "    Estimated time: 5-15 minutes\n",
    "    \"\"\"\n",
    "    print(\"=== SINGLE SUBJECT MMLU BENCHMARK ===\")\n",
    "    print(f\"🎯 Testing ONLY: {TARGET_SUBJECT}\")\n",
    "    print(\"📊 Math is the gold standard for AI reasoning capabilities\")\n",
    "    print(\"⏰ Estimated time: 5-15 minutes\")\n",
    "    print(\"💰 Cost: Very low API usage\\n\")\n",
    "\n",
    "    # Quick start\n",
    "    print(\"▶️  Starting in 2 seconds...\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Load MMLU dataset\n",
    "    print(\"📚 Loading MMLU dataset...\")\n",
    "    try:\n",
    "        dataset = load_dataset(\"cais/mmlu\", \"all\")\n",
    "        test_data = dataset[\"test\"]\n",
    "        print(f\"✅ Loaded {len(test_data)} total test questions\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    # Filter for target subject only\n",
    "    subject_questions = [q for q in test_data if q[\"subject\"] == TARGET_SUBJECT]\n",
    "    \n",
    "    if not subject_questions:\n",
    "        print(f\"❌ No questions found for {TARGET_SUBJECT}\")\n",
    "        return\n",
    "        \n",
    "    total_questions = len(subject_questions)\n",
    "    print(f\"🎯 Found {total_questions} questions for {TARGET_SUBJECT}\")\n",
    "\n",
    "    results = []\n",
    "    correct_answers = 0\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Create session for connection reuse and better performance\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"Content-Type\": \"application/json\"})\n",
    "\n",
    "    print(f\"\\n🔬 Testing subject: {TARGET_SUBJECT}\")\n",
    "    print(f\"   📊 Processing {total_questions} questions...\")\n",
    "\n",
    "    for i, question in enumerate(subject_questions):\n",
    "        if (i + 1) % 10 == 0 or i == 0:  # Progress every 10 questions\n",
    "            print(f\"   Question {i+1}/{total_questions}...\", end=\" \")\n",
    "\n",
    "        # Format question for the API\n",
    "        choices = [question[\"choices\"][j] for j in range(len(question[\"choices\"]))]\n",
    "        question_text = f\"\"\"Question: {question['question']}\n",
    "        \n",
    "A) {choices[0]}\n",
    "B) {choices[1]}\n",
    "C) {choices[2]}\n",
    "D) {choices[3]}\n",
    "\n",
    "Please answer with only the letter (A, B, C, or D).\"\"\"\n",
    "\n",
    "        # Prepare API request with varied parameters for testing\n",
    "        chat_data = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": question_text}],\n",
    "            \"max_tokens\": 10,\n",
    "            \"temperature\": 0.1,  # Low temperature for consistent answers\n",
    "            \"provider_constraint\": [\"openai\", \"deepseek\", \"anthropic\"],  # Multiple providers\n",
    "            \"cost_bias\": random.uniform(0.2, 0.8)  # Vary cost bias to test routing\n",
    "        }\n",
    "\n",
    "        # Retry logic for failed requests\n",
    "        max_retries = 3\n",
    "        retry_delay = 1\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                request_start_time = time.time()\n",
    "                response = session.post(\n",
    "                    f\"{BASE_URL}/v1/chat/completions\",\n",
    "                    json=chat_data,\n",
    "                    timeout=90  # Increased timeout to 90 seconds\n",
    "                )\n",
    "            response_time = time.time() - request_start_time\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                ai_answer = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "                # Extract adaptive backend selection info\n",
    "                selected_model = result.get(\"model\", \"unknown\")\n",
    "                selected_provider = result.get(\"provider\", \"unknown\")\n",
    "\n",
    "                # Extract letter from AI response\n",
    "                ai_letter = None\n",
    "                for char in ai_answer.upper():\n",
    "                    if char in ['A', 'B', 'C', 'D']:\n",
    "                        ai_letter = char\n",
    "                        break\n",
    "\n",
    "                # Convert correct answer index to letter\n",
    "                correct_letter = ['A', 'B', 'C', 'D'][question[\"answer\"]]\n",
    "\n",
    "                is_correct = ai_letter == correct_letter\n",
    "                if is_correct:\n",
    "                    correct_answers += 1\n",
    "\n",
    "                # Store result with detailed backend selection info\n",
    "                results.append({\n",
    "                    \"subject\": TARGET_SUBJECT,\n",
    "                    \"question_id\": f\"{TARGET_SUBJECT}_{i}\",\n",
    "                    \"question\": question[\"question\"][:200] + \"...\",\n",
    "                    \"correct_answer\": correct_letter,\n",
    "                    \"ai_answer\": ai_letter,\n",
    "                    \"ai_response_full\": ai_answer,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"response_time\": response_time,\n",
    "                    \"selected_model\": selected_model,\n",
    "                    \"selected_provider\": selected_provider,\n",
    "                    \"model_provider_combo\": f\"{selected_provider}/{selected_model}\",\n",
    "                    \"completion_tokens\": result.get(\"usage\", {}).get(\"completion_tokens\", 0),\n",
    "                    \"prompt_tokens\": result.get(\"usage\", {}).get(\"prompt_tokens\", 0),\n",
    "                    \"total_tokens\": result.get(\"usage\", {}).get(\"total_tokens\", 0),\n",
    "                    \"cost_bias_used\": chat_data[\"cost_bias\"],\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                })\n",
    "\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    accuracy_so_far = (correct_answers / (i + 1)) * 100\n",
    "                    print(f\"✅ Accuracy: {accuracy_so_far:.1f}%\")\n",
    "\n",
    "            else:\n",
    "                print(f\"❌ API Error: {response.status_code}\")\n",
    "                # Still record failed attempts\n",
    "                results.append({\n",
    "                    \"subject\": TARGET_SUBJECT,\n",
    "                    \"question_id\": f\"{TARGET_SUBJECT}_{i}\",\n",
    "                    \"question\": question[\"question\"][:200] + \"...\",\n",
    "                    \"correct_answer\": ['A', 'B', 'C', 'D'][question[\"answer\"]],\n",
    "                    \"ai_answer\": None,\n",
    "                    \"ai_response_full\": f\"API Error: {response.status_code}\",\n",
    "                    \"is_correct\": False,\n",
    "                    \"response_time\": 0,\n",
    "                    \"selected_model\": \"error\",\n",
    "                    \"selected_provider\": \"error\",\n",
    "                    \"model_provider_combo\": \"error/error\",\n",
    "                    \"completion_tokens\": 0,\n",
    "                    \"prompt_tokens\": 0,\n",
    "                    \"total_tokens\": 0,\n",
    "                    \"cost_bias_used\": chat_data[\"cost_bias\"],\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Request failed: {str(e)}\")\n",
    "            # Record failed requests\n",
    "            results.append({\n",
    "                \"subject\": TARGET_SUBJECT,\n",
    "                \"question_id\": f\"{TARGET_SUBJECT}_{i}\",\n",
    "                \"question\": question[\"question\"][:200] + \"...\",\n",
    "                \"correct_answer\": ['A', 'B', 'C', 'D'][question[\"answer\"]],\n",
    "                \"ai_answer\": None,\n",
    "                \"ai_response_full\": f\"Exception: {str(e)}\",\n",
    "                \"is_correct\": False,\n",
    "                \"response_time\": 0,\n",
    "                \"selected_model\": \"failed\",\n",
    "                \"selected_provider\": \"failed\",\n",
    "                \"model_provider_combo\": \"failed/failed\",\n",
    "                \"completion_tokens\": 0,\n",
    "                \"prompt_tokens\": 0,\n",
    "                \"total_tokens\": 0,\n",
    "                \"cost_bias_used\": chat_data[\"cost_bias\"],\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "\n",
    "        # Small delay to avoid overwhelming the API\n",
    "        time.sleep(0.03)\n",
    "\n",
    "    # Calculate final results\n",
    "    overall_accuracy = (correct_answers / len(results)) * 100 if results else 0\n",
    "    total_time = datetime.now() - start_time\n",
    "    successful_requests = sum(1 for r in results if r[\"selected_model\"] not in [\"error\", \"failed\"])\n",
    "\n",
    "    print(f\"\\n   📊 {TARGET_SUBJECT}: {correct_answers}/{len(results)} ({overall_accuracy:.1f}%)\")\n",
    "\n",
    "    print(\"\\n🎯 SINGLE SUBJECT BENCHMARK RESULTS:\")\n",
    "    print(f\"📊 Overall Accuracy: {correct_answers}/{len(results)} ({overall_accuracy:.1f}%)\")\n",
    "    print(f\"⏱️  Total Time: {total_time}\")\n",
    "    print(f\"✅ Successful Requests: {successful_requests}/{len(results)} ({successful_requests/len(results)*100:.1f}%)\")\n",
    "    if successful_requests > 0:\n",
    "        avg_response_time = sum(r['response_time'] for r in results if r['response_time'] > 0) / successful_requests\n",
    "        print(f\"⚡ Average Response Time: {avg_response_time:.2f}s\")\n",
    "\n",
    "    # Create comprehensive results DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    if len(df) > 0:\n",
    "        print(\"\\n📈 MATHEMATICS PERFORMANCE ANALYSIS:\")\n",
    "\n",
    "        # Filter successful requests for analysis\n",
    "        successful_df = df[df['selected_model'].isin(['error', 'failed']) == False]\n",
    "        \n",
    "        if len(successful_df) > 0:\n",
    "            print(\"\\n🤖 ADAPTIVE BACKEND MODEL SELECTION:\")\n",
    "            model_provider_usage = successful_df['model_provider_combo'].value_counts()\n",
    "            for combo, count in model_provider_usage.items():\n",
    "                accuracy = successful_df[successful_df['model_provider_combo'] == combo]['is_correct'].mean() * 100\n",
    "                avg_time = successful_df[successful_df['model_provider_combo'] == combo]['response_time'].mean()\n",
    "                print(f\"  {combo}: {count:,} questions ({count/len(successful_df)*100:.1f}%) - Accuracy: {accuracy:.1f}% - Avg Time: {avg_time:.2f}s\")\n",
    "\n",
    "            print(\"\\n💰 TOKEN USAGE ANALYSIS:\")\n",
    "            total_tokens_used = successful_df['total_tokens'].sum()\n",
    "            avg_tokens_per_question = successful_df['total_tokens'].mean()\n",
    "            print(f\"  Total tokens consumed: {total_tokens_used:,}\")\n",
    "            print(f\"  Average tokens per question: {avg_tokens_per_question:.1f}\")\n",
    "            print(f\"  Estimated API cost (rough): ${total_tokens_used * 0.000002:.4f}\")\n",
    "\n",
    "            if len(successful_df) > 1:  # Need multiple rows for groupby\n",
    "                provider_token_usage = successful_df.groupby('selected_provider')['total_tokens'].agg(['sum', 'mean', 'count']).round(1)\n",
    "                print(\"\\n📊 TOKEN USAGE BY PROVIDER:\")\n",
    "                for provider in provider_token_usage.index:\n",
    "                    total = provider_token_usage.loc[provider, 'sum']\n",
    "                    avg = provider_token_usage.loc[provider, 'mean']\n",
    "                    count = provider_token_usage.loc[provider, 'count']\n",
    "                    print(f\"  {provider}: {total:,} total tokens ({avg:.1f} avg) across {count:,} questions\")\n",
    "\n",
    "            # Cost bias analysis\n",
    "            print(\"\\n💸 COST BIAS EFFECTIVENESS:\")\n",
    "            successful_df['cost_bias_bin'] = pd.cut(successful_df['cost_bias_used'], bins=[0, 0.3, 0.7, 1.0], labels=['Low (0-0.3)', 'Med (0.3-0.7)', 'High (0.7-1.0)'])\n",
    "            if len(successful_df) > 1:\n",
    "                cost_bias_analysis = successful_df.groupby('cost_bias_bin').agg({\n",
    "                    'selected_model': lambda x: x.mode().iloc[0] if not x.empty else 'unknown',\n",
    "                    'selected_provider': lambda x: x.mode().iloc[0] if not x.empty else 'unknown',\n",
    "                    'is_correct': 'mean',\n",
    "                    'total_tokens': 'mean'\n",
    "                }).round(3)\n",
    "                print(cost_bias_analysis)\n",
    "\n",
    "        # Save results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"mmlu_math_benchmark_{timestamp}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        print(f\"\\n💾 Results saved: {filename}\")\n",
    "\n",
    "        print(\"\\n🔄 ADAPTIVE ROUTING EFFECTIVENESS:\")\n",
    "        print(f\"  Total questions tested: {len(df):,}\")\n",
    "        print(f\"  Subject: Mathematics (High School Level)\")\n",
    "        if len(successful_df) > 0:\n",
    "            print(f\"  Unique model/provider combinations: {len(model_provider_usage)}\")\n",
    "            print(f\"  Most used combination: {model_provider_usage.index[0] if len(model_provider_usage) > 0 else 'N/A'}\")\n",
    "        \n",
    "        print(f\"\\n🎯 MATHEMATICS BENCHMARK INSIGHTS:\")\n",
    "        print(f\"  🧮 Math reasoning accuracy: {overall_accuracy:.1f}%\")\n",
    "        print(f\"  🚀 Questions per minute: {len(df) / total_time.total_seconds() * 60:.1f}\")\n",
    "        print(f\"  📊 Success rate: {successful_requests/len(df)*100:.1f}%\")\n",
    "        \n",
    "        # Performance categorization\n",
    "        if overall_accuracy >= 70:\n",
    "            print(f\"  🏆 Performance: Excellent mathematical reasoning!\")\n",
    "        elif overall_accuracy >= 50:\n",
    "            print(f\"  👍 Performance: Good mathematical capabilities\")\n",
    "        else:\n",
    "            print(f\"  📈 Performance: Needs improvement on math problems\")\n",
    "\n",
    "    print(\"\\n✨ MATHEMATICS BENCHMARK FINISHED!\")\n",
    "    print(f\"🏁 Total time: {total_time}\")\n",
    "    print(f\"📊 Math accuracy: {overall_accuracy:.1f}%\")\n",
    "    print(\"🚀 Perfect for quick validation of reasoning capabilities!\")\n",
    "    return df\n",
    "\n",
    "# Run the single subject benchmark\n",
    "print(\"🧮 MMLU MATHEMATICS BENCHMARK\")\n",
    "print(\"🎯 Focus on the most important subject for AI reasoning\")\n",
    "print(\"⚡ Fast, focused, and comprehensive analysis\\n\")\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "random.seed(42)\n",
    "\n",
    "# Run it!\n",
    "math_results = run_single_subject_mmlu_benchmark()\n",
    "\n",
    "print(\"\\n🎉 MATHEMATICS BENCHMARK COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL SELECTION COMPARISON TEST ===\n",
      "🧪 Test Prompt: 'Explain quantum computing in simple terms.'\n",
      "\n",
      "🔍 Testing Python AI Service: /predict\n",
      "✅ Status: 200 | Time: 0.41s\n",
      "📄 Protocol: minion | Model: groq/llama-3.1-8b-instant\n",
      "\n",
      "🔍 Testing Go Backend: /v1/chat/completions\n",
      "✅ Status: 200 | Time: 1.68s\n",
      "📄 Final Selection: groq/llama-3.1-8b-instant\n",
      "\n",
      "==================================================\n",
      "🔍 COMPARISON ANALYSIS:\n",
      "🐍 Python Service Suggests: groq/llama-3.1-8b-instant\n",
      "🔧 Go Backend Actually Used: groq/llama-3.1-8b-instant\n",
      "✅ MATCH: Go backend used Python service recommendation!\n",
      "\n",
      "✨ Comparison test complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "BASE_URL = \"https://backend-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io\"\n",
    "PYTHON_SERVICE_URL = \"https://prompt-classifer-dev.mangoplant-a7a21605.swedencentral.azurecontainerapps.io\"\n",
    "\n",
    "def test_service(url, endpoint, data, service_name):\n",
    "    \"\"\"Test a service and return the result\"\"\"\n",
    "    full_url = f\"{url.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    print(f\"\\n🔍 Testing {service_name}: {endpoint}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        response = requests.post(full_url, headers=headers, json=data, timeout=15)\n",
    "        response_time = time.time() - start_time\n",
    "\n",
    "        print(f\"✅ Status: {response.status_code} | Time: {response_time:.2f}s\")\n",
    "        result = response.json()\n",
    "\n",
    "        # Extract key info\n",
    "        if service_name == \"Python AI Service\":\n",
    "            protocol = result.get(\"protocol\", \"unknown\")\n",
    "            model_info = result.get(\"minion\", {}).get(\"model\") or result.get(\"standard\", {}).get(\"model\")\n",
    "            provider_info = result.get(\"minion\", {}).get(\"provider\") or result.get(\"standard\", {}).get(\"provider\")\n",
    "            print(f\"📄 Protocol: {protocol} | Model: {provider_info}/{model_info}\")\n",
    "        else:  # Go Backend\n",
    "            model = result.get(\"model\", \"unknown\")\n",
    "            provider = result.get(\"provider\", \"unknown\")\n",
    "            print(f\"📄 Final Selection: {provider}/{model}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test prompt\n",
    "test_prompt = \"Explain quantum computing in simple terms.\"\n",
    "\n",
    "print(\"=== MODEL SELECTION COMPARISON TEST ===\")\n",
    "print(f\"🧪 Test Prompt: '{test_prompt}'\")\n",
    "\n",
    "# Test Python AI Service directly\n",
    "python_data = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "    \"provider_constraint\": [\"openai\", \"deepseek\"],\n",
    "    \"cost_bias\": 0.8\n",
    "}\n",
    "\n",
    "python_result = test_service(PYTHON_SERVICE_URL, \"/predict\", python_data, \"Python AI Service\")\n",
    "\n",
    "# Test Go Backend (which should call Python service internally)\n",
    "go_data = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "    \"provider_constraint\": [\"openai\", \"deepseek\"],\n",
    "    \"cost_bias\": 0.8\n",
    "}\n",
    "\n",
    "go_result = test_service(BASE_URL, \"/v1/chat/completions\", go_data, \"Go Backend\")\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"🔍 COMPARISON ANALYSIS:\")\n",
    "\n",
    "if python_result or go_result:\n",
    "    # Extract models for comparison\n",
    "    python_model = None\n",
    "    go_model = go_result.get(\"model\")\n",
    "\n",
    "    if python_result.get(\"protocol\") == \"minion\":\n",
    "        python_model = f\"{python_result.get('minion', {}).get('provider')}/{python_result.get('minion', {}).get('model')}\"\n",
    "    elif python_result.get(\"protocol\") == \"standard\":\n",
    "        python_model = f\"{python_result.get('standard', {}).get('provider')}/{python_result.get('standard', {}).get('model')}\"\n",
    "\n",
    "    go_model_full = f\"{go_result.get('provider')}/{go_result.get('model')}\"\n",
    "\n",
    "    print(f\"🐍 Python Service Suggests: {python_model}\")\n",
    "    print(f\"🔧 Go Backend Actually Used: {go_model_full}\")\n",
    "\n",
    "    if python_model and python_model.lower() in go_model_full.lower():\n",
    "        print(\"✅ MATCH: Go backend used Python service recommendation!\")\n",
    "    else:\n",
    "        print(\"⚠️  DIFFERENT: Go backend used different model (fallback or override)\")\n",
    "else:\n",
    "    print(\"❌ Cannot compare - one or both services failed\")\n",
    "\n",
    "print(\"\\n✨ Comparison test complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
