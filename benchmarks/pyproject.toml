[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["humaneval"]

[project]
name = "adaptive-benchmarks"
version = "0.1.0"
description = "LLM Benchmarking Suite with DeepEval Integration"
authors = [{ name = "Botir Khaltaev", email = "botirkhaltaev@llmadaptive.uk" }]
requires-python = ">=3.10,<4.0"
readme = "README.md"
license = "MIT"
keywords = ["llm", "benchmarks", "evaluation", "deepeval", "humaneval"]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Intended Audience :: Developers",
  "License :: OSI Approved :: MIT License",
  "Operating System :: OS Independent",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",
  "Typing :: Typed",
]
dependencies = [
  # Core DeepEval Framework
  "deepeval>=1.0.0",

  # LLM Provider SDKs
  "anthropic>=0.40.0",
  "openai>=1.0.0",

  # Token Counting & Cost Tracking
  "tiktoken>=0.7.0",

  # HTTP & API Clients
  "requests>=2.31.0",
  "httpx>=0.27.0",

  # Testing Framework
  "pytest>=8.4.1",
  "pytest-asyncio>=0.23.0",

  # Data Processing & Analysis
  "pandas>=2.0.0",
  "numpy>=1.24.0",
  "datasets>=2.0.0",

  # Environment Management
  "python-dotenv>=1.0.0",

  # Utilities
  "tqdm>=4.66.0",
  "python-dateutil>=2.8.0",
  "pydantic>=2.0.0",

  # Type Hints
  "typing-extensions>=4.9.0",
]

[project.optional-dependencies]
viz = [
  "matplotlib>=3.7.0",
  "seaborn>=0.12.0",
]

[dependency-groups]
dev = [
  "mypy>=1.15.0,<2",
  "black>=25.1.0,<26",
  "ruff>=0.11.11,<0.14",
  "pytest>=8.4.1",
  "pytest-cov>=6.2.1",
  "pytest-asyncio>=0.26.0",
  "types-requests>=2.31.0",
]

[tool.black]
line-length = 88
target-version = ['py310', 'py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | venv
  | _build
  | build
  | dist
  | _archived
  | MMLU benchmark
  | MMLU-Pro
  | genai-perf
  | protocol-model-testing
)/
'''

[tool.ruff]
line-length = 88
target-version = "py310"
extend-exclude = [
  ".eggs",
  ".git",
  ".mypy_cache",
  ".venv",
  "venv",
  "_build",
  "build",
  "dist",
  "_archived",
  "MMLU benchmark",
  "MMLU-Pro",
  "genai-perf",
  "protocol-model-testing",
]

[tool.ruff.lint]
select = [
  "E",   # pycodestyle errors
  "W",   # pycodestyle warnings
  "F",   # pyflakes
  "I",   # isort
  "B",   # flake8-bugbear
  "C4",  # flake8-comprehensions
  "UP",  # pyupgrade
]
ignore = [
  "E501",  # line too long (handled by black)
  "B008",  # do not perform function calls in argument defaults
  "C901",  # too complex
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]  # Allow unused imports in __init__.py

[tool.mypy]
python_version = "3.10"
exclude = [
  "MMLU benchmark/",
  "MMLU-Pro/",
  "genai-perf/",
  "protocol-model-testing/",
  "_archived/",
]
no_implicit_optional = true
warn_return_any = false
warn_unused_ignores = true
disallow_untyped_defs = false  # DeepEval has some untyped code

[[tool.mypy.overrides]]
module = [
  "deepeval.*",
  "anthropic.*",
  "tiktoken.*",
  "pandas.*",
  "numpy.*",
  "matplotlib.*",
  "seaborn.*",
  "tqdm.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["humaneval/tests"]
markers = [
  "unit: marks tests as unit tests (no external dependencies)",
  "integration: marks tests as integration tests (requires API keys)",
  "slow: marks tests as slow tests (full benchmarks)",
  "quick: marks tests as quick tests (subset of tasks)",
]
addopts = "-v --strict-markers"
asyncio_mode = "auto"

[tool.coverage.run]
source = ["humaneval"]
omit = [
  "*/tests/*",
  "*/__init__.py",
  "*/venv/*",
  "*/.venv/*",
]

[tool.coverage.report]
exclude_lines = [
  "pragma: no cover",
  "def __repr__",
  "if self.debug:",
  "if settings.DEBUG",
  "raise AssertionError",
  "raise NotImplementedError",
  "if 0:",
  "if __name__ == .__main__.:",
  "class .*\\bProtocol\\):",
  "@(abc\\.)?abstractmethod",
]
precision = 2
show_missing = true
