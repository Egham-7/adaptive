---
title: "Langchain Integration"
description: "Connect LangChain (Python & JS) with Adaptive for intelligent routing."
sidebarTitle: "LangChain"
---

## Overview

Use Adaptive as your OpenAI-compatible base URL in LangChain to enable intelligent routing, streaming, and cost optimizations.

## Installation

<Tabs>
<Tab title="Python">
```bash
pip install langchain langchain-openai
````

</Tab>
<Tab title="JavaScript">
```bash
npm install langchain @langchain/openai
```
</Tab>
</Tabs>

## Quick Start

### Python

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(api_key="ADAPTIVE_KEY", base_url="https://llmadaptive.uk/api/v1", model="")
response = llm.invoke("Explain ML simply")
print(response.content)
```

### JavaScript

```js
import { ChatOpenAI } from "@langchain/openai";
const llm = new ChatOpenAI({
  apiKey: "ADAPTIVE_KEY",
  baseURL: "https://llmadaptive.uk/api/v1",
  model: "",
});
const res = await llm.invoke("Explain quantum computing");
console.log(res.content);
```

## Advanced Usage

### Streaming

```python
for chunk in llm.stream("Tell me a story"):
    print(chunk.content, end="")
```

### Cost & Provider Constraints

```python
llm = ChatOpenAI(..., model_kwargs={"provider_constraint":["openai","anthropic"], "cost_bias":0.2})
```

## Extras

- **Function calling**, **tools**, **chains**, **memory** support â€” works out of the box.
- For embeddings, use OpenAI's API (embeddings coming soon!).

## Migration

Simply switch:

```diff
- model="gpt-3.5-turbo"
+ model=""           # for Adaptive
```

## Best Practices

| Tip                            | Description                           |
| ------------------------------ | ------------------------------------- |
| **Leave `model=""`**           | Enables intelligent routing           |
| **Use `cost_bias`**            | Adjusts performance vs cost           |
| **Add `provider_constraint`** | Controls which API providers are used |
| **Handle errors**              | Wrap calls in try/catch or retries    |

