---
title: "Introduction"
description: "Welcome to Adaptive - the most intelligent LLM inference platform designed for modern developers."
icon: "sparkles"
---

<div className="relative">
  <div className="px-4 py-16 lg:py-24 max-w-4xl mx-auto">
    <h1 className="block text-4xl font-bold text-center text-gray-900 dark:text-zinc-50 tracking-tight">
      The Most Intelligent LLM Inference Platform
    </h1>

    <div className="max-w-2xl mx-auto px-4 mt-6 text-xl text-center text-gray-600 dark:text-zinc-400">
      Adaptive automatically routes your AI requests to the optimal model across multiple providers, delivering exceptional performance while dramatically reducing costs.
    </div>

    <div className="flex justify-center mt-8">
      <div className="inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-md text-white bg-gradient-to-r from-yellow-500 to-yellow-600 hover:from-yellow-600 hover:to-yellow-700 transition-colors">
        âœ¨ Drop-in OpenAI replacement with zero code changes
      </div>
    </div>
  </div>
</div>

## Why Choose Adaptive?

<CardGroup cols={2}>
  <Card title="Intelligent Routing" icon="brain">
    Our AI analyzes each request and automatically selects the optimal model based on complexity, performance requirements, and cost efficiency.
  </Card>
  <Card title="Seamless Integration" icon="plug">
    Drop-in replacement for OpenAI API. Simply change your base URL and everything works immediately.
  </Card>
  <Card title="Multi-Provider Access" icon="network-wired">
    Access leading AI providers including OpenAI, Anthropic, Google, Groq, DeepSeek, and Grok through one unified interface.
  </Card>
  <Card title="Enterprise Ready" icon="shield-check">
    Built for scale with advanced caching, fallback mechanisms, and comprehensive monitoring and analytics.
  </Card>
</CardGroup>

## How Adaptive Works

<Steps>
  <Step title="Intelligent Analysis">
    Every request is analyzed in real-time to understand complexity, context, and requirements
  </Step>
  <Step title="Optimal Routing">
    Our AI selects the best model across multiple providers for performance, cost, and quality
  </Step>
  <Step title="Seamless Response">
    Receive consistent OpenAI-compatible responses regardless of the underlying provider
  </Step>
  <Step title="Continuous Learning">
    The system learns from each interaction to improve routing decisions over time
  </Step>
</Steps>

## Platform Capabilities

<CardGroup cols={3}>
  <Card title="Smart Routing" icon="route">
    Advanced AI algorithms analyze each request to determine the optimal model and provider combination.
  </Card>
  <Card title="Cost Optimization" icon="trending-down">
    Achieve significant cost reductions through intelligent model selection and efficient request routing.
  </Card>
  <Card title="Performance" icon="zap">
    Lightning-fast response times with built-in caching and optimized provider connections.
  </Card>
</CardGroup>

## Advanced Features

<CardGroup cols={3}>
  <Card title="Semantic Caching" icon="database">
    Intelligent caching system that understands context and meaning to deliver faster responses.
  </Card>
  <Card title="Provider Resiliency" icon="shield">
    Automatic failover and circuit breaker patterns ensure high availability and reliability.
  </Card>
  <Card title="Real-time Analytics" icon="chart-line">
    Comprehensive monitoring and insights into usage patterns, performance metrics, and optimization opportunities.
  </Card>
</CardGroup>

## Supported AI Providers

<CardGroup cols={2}>
  <Card title="Leading AI Models" icon="stars">
    Access the latest models from OpenAI, Anthropic, Google Gemini, Groq, DeepSeek, and Grok through one unified interface.
  </Card>
  <Card title="Always Up-to-Date" icon="refresh">
    Automatically gain access to new models as they're released, without code changes or integration work.
  </Card>
</CardGroup>

<Accordion title="View All Supported Models">

**OpenAI**
- GPT-4o, GPT-4o Mini, GPT-4 Turbo, GPT-3.5 Turbo

**Anthropic**  
- Claude 4 Sonnet, Claude 3.5 Sonnet, Claude 3.5 Haiku, Claude 3 Opus

**Google Gemini**
- Gemini 2.5 Pro, Gemini 2.5 Pro Large, Gemini 2.0 Flash, Gemini 1.5 Flash

**Groq (Ultra-fast)**
- Llama 4 Scout 17B, Llama 4 Maverick 17B, Llama 3.3 70B, DeepSeek R1 Distill

**DeepSeek (Advanced reasoning)**
- DeepSeek Reasoner, DeepSeek Chat

**Grok (xAI)**
- Grok 3, Grok 3 Fast, Grok 3 Mini, Grok Beta

</Accordion>

## Get Started in Minutes

<CardGroup cols={2}>
  <Card title="Quick Start Guide" icon="rocket" href="/quickstart">
    Follow our step-by-step guide to integrate Adaptive into your application in under 5 minutes.
  </Card>
  <Card title="API Reference" icon="book" href="/api-reference/introduction">
    Explore our comprehensive API documentation with interactive examples and detailed specifications.
  </Card>
</CardGroup>

## Popular Integrations

<CardGroup cols={2}>
  <Card title="OpenAI SDK" href="/integrations/openai-sdk" icon="code">
    Use with official OpenAI SDK for JavaScript, Python, and other languages
  </Card>
  <Card title="Vercel AI SDK" href="/integrations/vercel-ai-sdk" icon="nextjs">
    Stream responses and build AI chat applications with Vercel AI SDK
  </Card>
  <Card title="LangChain" href="/integrations/langchain" icon="link">
    Integrate with LangChain workflows and chains for complex AI applications
  </Card>
  <Card title="Direct API" href="/api-reference/chat-completions" icon="terminal">
    Use REST API directly with any HTTP client or programming language
  </Card>
</CardGroup>

## What Makes Adaptive Different

<CardGroup cols={3}>
  <Card title="Transparent Routing" icon="eye">
    Every response includes metadata showing which provider and model was selected, giving you full visibility into the routing decisions.
  </Card>
  <Card title="OpenAI Compatible" icon="check">
    All responses follow OpenAI format standards, ensuring seamless compatibility with existing tools and workflows.
  </Card>
  <Card title="Enhanced Metadata" icon="info">
    Additional insights including cache status, performance metrics, and routing rationale help you optimize your AI usage.
  </Card>
</CardGroup>

## Explore the Platform

<CardGroup cols={2}>
  <Card title="Intelligent Routing" icon="brain" href="/features/intelligent-routing">
    Discover how our AI-powered routing engine selects the optimal model for each request
  </Card>
  <Card title="Performance & Caching" icon="zap" href="/features/performance">
    Learn about our advanced caching strategies and performance optimizations
  </Card>
  <Card title="Provider Resiliency" icon="shield" href="/features/provider-resiliency">
    Understand our failover mechanisms and reliability features
  </Card>
  <Card title="Integration Examples" icon="code" href="/examples/basic-chat">
    See real-world examples and implementation patterns
  </Card>
</CardGroup>

---

<div className="text-center py-8">
  <h3 className="text-2xl font-semibold text-gray-900 dark:text-zinc-50 mb-4">
    Ready to optimize your AI infrastructure?
  </h3>
  <p className="text-lg text-gray-600 dark:text-zinc-400 mb-6">
    Join thousands of developers who have already upgraded to intelligent LLM routing.
  </p>
  <a 
    href="https://llmadaptive.uk/signup" 
    className="inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-md text-white bg-gradient-to-r from-yellow-500 to-yellow-600 hover:from-yellow-600 hover:to-yellow-700 transition-colors"
  >
    Get Started Free
  </a>
</div>