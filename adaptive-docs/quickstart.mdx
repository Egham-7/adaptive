---
title: '5-Minute Success: From $1000/month to $200/month'
description: 'Replace one line of code and start saving immediately'
icon: "rocket"
---

<div style="text-align: center; margin: 2rem 0; padding: 1.5rem; border: 2px solid #d4af37; border-radius: 8px; background: linear-gradient(135deg, #fdf6e3 0%, #f7f1d3 100%);">
  <div style="font-size: 1.8rem; font-weight: bold; color: #d4af37; margin-bottom: 0.5rem;">
    ‚ö° 5-Minute Success Path
  </div>
  <div style="font-size: 1rem; color: #666;">
    One URL change ‚Üí Instant 60-80% savings ‚Üí Same quality responses
  </div>
</div>

## Step 1: Copy This URL (30 seconds)

Replace your OpenAI base URL with this single line:

```
https://llmadaptive.uk/api/v1
```

**That's literally it.** Your existing code works immediately.

---

## Step 2: Get Your Free API Key (2 minutes)

<Steps>
  <Step title="Sign Up Free">
    Visit [llmadaptive.uk](https://llmadaptive.uk) (no credit card required)
  </Step>
  <Step title="Generate Key">
    Click "Generate API Key" ‚Üí Copy your key
  </Step>
  <Step title="You're Done">
    Total time: 2 minutes
  </Step>
</Steps>

---

## Step 3: Update Your Code (1 minute)

<Tabs>
<Tab title="JavaScript/TypeScript">
```javascript Before ‚Üí After
// Before: Expensive
const openai = new OpenAI({
  apiKey: 'sk-your-openai-key',
  baseURL: 'https://api.openai.com/v1'        // ‚ùå
});

// After: Smart & Cheap  
const openai = new OpenAI({
  apiKey: 'your-adaptive-key',                // ‚úÖ Your new key
  baseURL: 'https://llmadaptive.uk/api/v1'   // ‚úÖ Only change needed
});

// Everything else stays exactly the same
const response = await openai.chat.completions.create({
  model: '',  // ‚Üê Leave empty for intelligent routing
  messages: [{ role: 'user', content: 'Hello!' }]
});
```
</Tab>
<Tab title="Python">
```python Before ‚Üí After
# Before: Expensive
client = OpenAI(
    api_key="sk-your-openai-key",
    base_url="https://api.openai.com/v1"      # ‚ùå
)

# After: Smart & Cheap
client = OpenAI(
    api_key="your-adaptive-key",              # ‚úÖ Your new key
    base_url="https://llmadaptive.uk/api/v1"  # ‚úÖ Only change needed
)

# Everything else stays exactly the same
response = client.chat.completions.create(
    model="",  # ‚Üê Leave empty for intelligent routing
    messages=[{"role": "user", "content": "Hello!"}]
)
```
</Tab>
<Tab title="cURL">
```bash Before ‚Üí After
# Before: Expensive
curl https://api.openai.com/v1/chat/completions \  # ‚ùå
  -H "Authorization: Bearer sk-your-openai-key" \
  -d '{"model": "gpt-4", "messages": [...]}'

# After: Smart & Cheap
curl https://llmadaptive.uk/api/v1/chat/completions \  # ‚úÖ
  -H "X-Stainless-API-Key: your-adaptive-key" \
  -d '{"model": "", "messages": [...]}'  # ‚Üê Empty model for routing
```
</Tab>
</Tabs>

---

## Step 4: Test & See Immediate Savings (2 minutes)

Run your code and watch the magic happen:

```json Response shows which provider was chosen
{
  "id": "chatcmpl-abc123",
  "choices": [{
    "message": {"content": "Hello! I'm ready to help."}
  }],
  "provider": "gemini",     // ‚Üê Adaptive chose Gemini (97% cheaper!)
  "usage": {
    "total_tokens": 15,
    "cache_tier": "none"    // ‚Üê Cache status for performance tracking
  }
}
```

<Note>
**Success!** You just made your first intelligent API call. Simple questions automatically route to cheap models like Gemini Flash, while complex tasks use premium models when needed.
</Note>

---

## Your Immediate Benefits

<CardGroup cols={2}>
  <Card title="üí∞ Instant Savings" icon="dollar-sign">
    **60-80% cost reduction** from your very first API call
    
    Simple chat: $3.00 ‚Üí $0.10 per 1M tokens
  </Card>
  <Card title="üöÄ Same Performance" icon="zap">
    **Identical response format** to OpenAI
    
    Your app works exactly the same way
  </Card>
  <Card title="üß† Smart Routing" icon="brain">
    **Automatic model selection** based on prompt complexity
    
    No manual model management needed
  </Card>
  <Card title="üîÑ 6+ Providers" icon="network-wired">
    **Access to all major AI providers** through one API
    
    OpenAI, Claude, Gemini, Groq, DeepSeek, Grok
  </Card>
</CardGroup>

---

## Verify Your Setup (Optional)

Want to confirm everything's working? Try this test:

<Tabs>
<Tab title="Simple Test">
```javascript Quick validation
const testResponse = await openai.chat.completions.create({
  model: '',
  messages: [{ role: 'user', content: 'Hi' }]
});

console.log(`Provider: ${testResponse.provider}`);
console.log(`Cost per token: Much cheaper than OpenAI!`);
```
</Tab>
<Tab title="Cost Comparison Test">
```javascript See the savings
// Test simple vs complex prompts
const simple = await openai.chat.completions.create({
  model: '',
  messages: [{ role: 'user', content: 'Hello' }]
});
console.log(`Simple ‚Üí ${simple.provider} (cheapest)`);

const complex = await openai.chat.completions.create({
  model: '',
  messages: [{ 
    role: 'user', 
    content: 'Write a detailed analysis of quantum computing applications in cryptography'
  }]
});
console.log(`Complex ‚Üí ${complex.provider} (best for task)`);
```
</Tab>
</Tabs>

---

## What Just Happened?

<Accordion title="üîç Behind the Scenes">
When you sent your first request:

1. **AI Analysis**: Our routing AI analyzed your prompt complexity
2. **Smart Selection**: Chose the optimal provider/model for your needs
3. **Cost Optimization**: Balanced quality vs. cost automatically
4. **Instant Response**: Returned OpenAI-compatible response

You got the best model for your task at the lowest possible cost, automatically.
</Accordion>

<Accordion title="üìä Your Savings Breakdown">
**For a typical $1,000/month OpenAI bill:**

- **Simple tasks** (60% of requests): Save $570/month
  - "Hello" ‚Üí Gemini Flash ($0.10 vs $3.00 per 1M tokens)
- **Medium tasks** (30% of requests): Save $210/month  
  - Code questions ‚Üí DeepSeek ($0.34 vs $10.00 per 1M tokens)
- **Complex tasks** (10% of requests): Save $20/month
  - Research ‚Üí Claude ($2.19 vs $15.00 per 1M tokens)

**Total monthly savings: $800** (80% reduction)
</Accordion>

---

## Next Steps (Choose Your Adventure)

<CardGroup cols={2}>
  <Card title="üéØ I Want More Control" href="/features/intelligent-routing">
    **Configure routing behavior**
    
    Cost bias, provider selection, caching options
  </Card>
  <Card title="‚ö° I Want Streaming" href="/integrations/vercel-ai-sdk">
    **Add streaming responses**
    
    Real-time chat with Vercel AI SDK
  </Card>
  <Card title="üîß I Use Frameworks" href="/integrations/langchain">
    **LangChain & other integrations**
    
    Drop-in replacement for popular frameworks
  </Card>
  <Card title="üìö I Want Examples" href="/examples/basic-chat">
    **See complete implementations**
    
    Working code for common use cases
  </Card>
</CardGroup>

---

## Having Issues? (Rare, but we're here)

<AccordionGroup>
<Accordion title="Authentication Error">
**Problem**: `401 Unauthorized` response

**Solution**: 
1. Check your API key in the request header
2. Use `X-Stainless-API-Key` header (not `Authorization`)
3. Verify your key is active at [llmadaptive.uk](https://llmadaptive.uk)
</Accordion>

<Accordion title="Different Response Format">
**Problem**: Response looks different from OpenAI

**Solution**: That's expected! We add helpful fields like `provider` and `cache_tier`. Your existing code reading `choices[0].message.content` still works perfectly.
</Accordion>

<Accordion title="Want Specific Model">
**Problem**: Need to use a specific model sometimes

**Solution**: 
```javascript
// For intelligent routing (recommended)
model: ""

// For specific provider/model
model: "anthropic/claude-3-sonnet-20240229"
```
</Accordion>
</AccordionGroup>

**Still stuck?** Email us at support@llmadaptive.uk or [join our Discord](https://discord.gg/adaptive) for instant help.