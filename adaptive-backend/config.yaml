---
# Adaptive Backend Configuration
# Environment variables can be referenced using ${VAR} or ${VAR:-default} syntax (defaults apply when a variable is unset or empty)

server:
  addr: "${ADDR:-:8080}"
  allowed_origins: "${ALLOWED_ORIGINS:-http://localhost:3000}"
  environment: "${ENV:-development}"
  log_level: "${LOG_LEVEL:-info}"
  jwt_secret: "${JWT_SECRET}"

# Endpoint-specific provider configurations
endpoints:
  chat_completions:
    providers:
      openai:
        api_key: "${OPENAI_API_KEY}"
        enabled: true
        native_format: "openai"

      anthropic:
        api_key: "${ANTHROPIC_API_KEY}"
        enabled: true
        base_url: "https://api.anthropic.com/v1"
        native_format: "openai"

      gemini:
        api_key: "${GEMINI_API_KEY}"
        enabled: true
        base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
        native_format: "openai"

      deepseek:
        api_key: "${DEEPSEEK_API_KEY}"
        enabled: true
        base_url: "https://api.deepseek.com"
        native_format: "openai"

      huggingface:
        api_key: "${HUGGINGFACE_API_KEY}"
        enabled: true
        base_url: "https://router.huggingface.co/v1"
        native_format: "openai"

  messages:
    providers:
      anthropic:
        api_key: "${ANTHROPIC_API_KEY}"
        enabled: true
        base_url: "https://api.anthropic.com"

      openai:
        api_key: "${OPENAI_API_KEY}"
        enabled: true
        native_format: "openai"

      gemini:
        api_key: "${GEMINI_API_KEY}"
        enabled: true
        base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
        native_format: "openai"

      deepseek:
        api_key: "${DEEPSEEK_API_KEY}"
        enabled: true
        base_url: "https://api.deepseek.com"
        native_format: "openai"

      huggingface:
        api_key: "${HUGGINGFACE_API_KEY}"
        enabled: true
        base_url: "https://router.huggingface.co/v1"
        native_format: "openai"

# Services configuration
services:
  adaptive_ai:
    base_url: "${ADAPTIVE_AI_BASE_URL:-http://localhost:8000}"

  redis:
    url: "${REDIS_URL:-redis://localhost:6379}"

# Fallback configuration
fallback:
  mode: "race" # "race" or "sequential"
  timeout_ms: 30000 # Keep longer for streaming LLM responses
  max_retries: 3
  circuit_breaker:
    failure_threshold: 5
    success_threshold: 3
    timeout_ms: 15000
    reset_after_ms: 60000

# Prompt cache configuration
prompt_cache:
  enabled: false
  default_ttl_seconds: 3600
  redis_url: "${REDIS_URL:-redis://localhost:6379}"

# Protocol manager configuration
protocol_manager:
  semantic_cache:
    enabled: true
    threshold: 0.95
    redis_url: "${REDIS_URL:-redis://localhost:6379}"
    openai_api_key: "${OPENAI_API_KEY}" # For embeddings
  client:
    base_url: "${ADAPTIVE_AI_BASE_URL:-http://localhost:8000}"
    timeout_ms: 3000
    circuit_breaker:
      failure_threshold: 3
      success_threshold: 2
      timeout_ms: 5000
      reset_after_ms: 30000
